{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69de1cb",
   "metadata": {
    "id": "c69de1cb"
   },
   "source": [
    "# `Recommender System Models`\n",
    "\n",
    "&emsp;&emsp;&emsp;<font size=\"4\">In this project, the user ratings from a subset of Amazon Reviews are used train a collaborative-filtering recommendation system by evaluating various algorithms with hyperparameter optimization. The models return a list of recommended items based on the reviewer's previous actions.<font>\n",
    "\n",
    "# `Data`\n",
    "&emsp;&emsp;&emsp;<font size=\"4\">The `Movies_and_TV` ratings data was retrieved from [here](https://jmcauley.ucsd.edu/data/amazon/). This includes (item, user, rating, timestamp) tuples. A subset of the data was used in the analysis due to constraints of sparcity for computation.<font>\n",
    "\n",
    "# `Preprocessing`\n",
    "&emsp;&emsp;&emsp;<font size=\"4\">The code that was used for preprocessing and EDA can be found [here](https://github.com/adataschultz/RecSys/blob/main/Notebooks_Scripts/Recommender_System.py). \n",
    "- First the environment is set up with the dependencies, library options, the seed for reproducibility, and setting the location of the project directory. Then the data is read, duplicate observations dropped and columns named.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704599b",
   "metadata": {
    "id": "7704599b",
    "outputId": "7ed48215-689a-42e0-e7e9-2b0cf9d75bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample observations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001527665</td>\n",
       "      <td>A2VHSG6TZHU1OB</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1361145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001527665</td>\n",
       "      <td>A23EJWOW1TLENE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1358380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001527665</td>\n",
       "      <td>A1KM9FNEJ8Q171</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1357776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001527665</td>\n",
       "      <td>A38LY2SSHVHRYB</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1356480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001527665</td>\n",
       "      <td>AHTYUW2H1276L</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1353024000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item      reviewerID  rating   timestamp\n",
       "0  0001527665  A2VHSG6TZHU1OB     5.0  1361145600\n",
       "1  0001527665  A23EJWOW1TLENE     5.0  1358380800\n",
       "2  0001527665  A1KM9FNEJ8Q171     5.0  1357776000\n",
       "3  0001527665  A38LY2SSHVHRYB     4.0  1356480000\n",
       "4  0001527665   AHTYUW2H1276L     5.0  1353024000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from surprise import Dataset, Reader, BaselineOnly, NormalPredictor\n",
    "from surprise import KNNBaseline, KNNWithMeans, KNNBasic, KNNWithZScore\n",
    "from surprise import SVD, SVDpp, NMF, CoClustering, dump, accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set seed \n",
    "seed_value = 42\n",
    "os.environ['Recommender'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Set path\n",
    "path = r'D:\\AmazonReviews\\Data'\n",
    "os.chdir(path)\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('Movies_and_TV.csv', header=None, skiprows=[0],\n",
    "                 low_memory=False)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Name columns\n",
    "df.columns = ['item', 'reviewerID', 'rating', 'timestamp']\n",
    "\n",
    "print('Sample observations:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02640729",
   "metadata": {
    "id": "02640729"
   },
   "source": [
    "<font size=\"4\">Then a function is defined to examine the data for the number of missing observations, data types and the amount of unique values in the initial set. The `timestamp` variable is dropped since it will not be used<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ba31c",
   "metadata": {
    "id": "992ba31c",
    "outputId": "abadcd15-aaa2-4d50-8596-fa8b56da081e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Summary:\n",
      "Number of Rows: 8522125, Columns: 4\n",
      "            Number of Missing Values Data type of variable  \\\n",
      "item                               0                object   \n",
      "reviewerID                         0                object   \n",
      "rating                             0               float64   \n",
      "timestamp                          0                 int64   \n",
      "\n",
      "            Number of Unique Values  \n",
      "item                         182032  \n",
      "reviewerID                  3826085  \n",
      "rating                            5  \n",
      "timestamp                      7476  \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a function to examine the data\n",
    "def data_summary(df):\n",
    "    print('Number of Rows: {}, Columns: {}'.format(df.shape[0], df.shape[1]))\n",
    "    a = pd.DataFrame()\n",
    "    a['Number of Missing Values'] = df.isnull().sum()\n",
    "    a['Data type of variable'] = df.dtypes\n",
    "    a['Number of Unique Values'] = df.nunique()\n",
    "    print(a)\n",
    "\n",
    "print('Initial Data Summary:')     \n",
    "print(data_summary(df))\n",
    "\n",
    "df = df.drop(['timestamp'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iCwCgPME-MCJ",
   "metadata": {
    "id": "iCwCgPME-MCJ"
   },
   "source": [
    "<font size=\"4\">The top 10 reviewers with the most number of ratings in the initial set shows that they have over 1,600 reviews.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd43870",
   "metadata": {
    "id": "8dd43870",
    "outputId": "26a02ca4-7ad1-4a67-c275-ca75b8d07170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewers with highest number of ratings in initial set:\n",
      "reviewerID\n",
      "AV6QDP8Q0ONK4     4101\n",
      "A1GGOC9PVDXW7Z    2114\n",
      "ABO2ZI2Y5DQ9T     2073\n",
      "A328S9RN3U5M68    2059\n",
      "A3MV1KKHX51FYT    1989\n",
      "A2EDZH51XHFA9B    1842\n",
      "A3LZGLA88K0LA0    1814\n",
      "A16CZRQL23NOIW    1808\n",
      "AIMR915K4YCN      1719\n",
      "A2NJO6YE954DBH    1699\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reviewers_top10 = df.groupby('reviewerID').size().sort_values(ascending=False)[:10]\n",
    "print('Reviewers with highest number of ratings in initial set:')\n",
    "print(reviewers_top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YoQ3n-Jk-RHM",
   "metadata": {
    "id": "YoQ3n-Jk-RHM"
   },
   "source": [
    "<font size=\"4\">The top 10 items in the initial set shows the highest item has 24,554 ratings while the 10th highest items has 14,174 ratings. <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401047a",
   "metadata": {
    "id": "b401047a",
    "outputId": "c2849693-9d35-4c60-a0ba-4e3030166f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items with highest number of ratings in initial set:\n",
      "item\n",
      "B00YSG2ZPA    24554\n",
      "B00006CXSS    24485\n",
      "B00AQVMZKQ    21015\n",
      "B01BHTSIOC    20889\n",
      "B00NAQ3EOK    16857\n",
      "6305837325    16671\n",
      "B00WNBABVC    15205\n",
      "B017S3OP7A    14795\n",
      "B009934S5M    14481\n",
      "B00FL31UF0    14174\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "items_top10 = df.groupby('item').size().sort_values(ascending=False)[:10]\n",
    "print('Items with highest number of ratings in initial set:')\n",
    "print(items_top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eff9c2-65cd-4578-9eaf-ed24b35bee4a",
   "metadata": {
    "id": "a5eff9c2-65cd-4578-9eaf-ed24b35bee4a"
   },
   "source": [
    "<font size=\"4\">Since the data is sparse, a new integer id is created for `item` rather the initial string variable. <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b392542",
   "metadata": {
    "id": "7b392542"
   },
   "outputs": [],
   "source": [
    "value_counts = df['item'].value_counts(dropna=True, sort=True)\n",
    "df1 = pd.DataFrame(value_counts)\n",
    "df1 = df1.reset_index()\n",
    "df1.columns = ['item_unique', 'counts'] \n",
    "df1 = df1.reset_index()\n",
    "df1.rename(columns={'index': 'item_id'}, inplace=True)\n",
    "df1 = df1.drop(['counts'], axis=1)\n",
    "df = pd.merge(df, df1, how='left', left_on=['item'],\n",
    "              right_on=['item_unique'])\n",
    "df = df.drop_duplicates()\n",
    "df = df.drop(['item_unique'], axis=1)\n",
    "\n",
    "del value_counts, df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3af13-5575-4dd6-9928-9bef55fc8f50",
   "metadata": {
    "id": "36c3af13-5575-4dd6-9928-9bef55fc8f50"
   },
   "source": [
    "<font size=\"4\">The same process is used for `reviewerID`. A key is created for merging the new integer variables that later be used to join the original data. For this set, the unnecessary keys are then dropped.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003f833",
   "metadata": {
    "id": "c003f833"
   },
   "outputs": [],
   "source": [
    "value_counts = df['reviewerID'].value_counts(dropna=True, sort=True)\n",
    "df1 = pd.DataFrame(value_counts)\n",
    "df1 = df1.reset_index()\n",
    "df1.columns = ['id_unique', 'counts'] \n",
    "df1 = df1.reset_index()\n",
    "df1.rename(columns={'index': 'reviewer_id'}, inplace=True)\n",
    "df1 = df1.drop(['counts'], axis=1)\n",
    "df = pd.merge(df, df1, how='left', left_on=['reviewerID'],\n",
    "              right_on=['id_unique'])\n",
    "df = df.drop_duplicates()\n",
    "df = df.drop(['id_unique'], axis=1)\n",
    "\n",
    "del value_counts, df1\n",
    "\n",
    "df1 = df[['item', 'item_id', 'reviewerID', 'reviewer_id']]\n",
    "df1.to_csv('Movies_and_TV_idMatch.csv', index=False)\n",
    "\n",
    "del df1\n",
    "\n",
    "df = df.drop(['item', 'reviewerID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4AVINFrj-b9m",
   "metadata": {
    "id": "4AVINFrj-b9m"
   },
   "source": [
    "<font size=\"4\">The data is then filtered to ratings/reviewers who have greater than or equal to 25 ratings/reviews due to sparsity. This results in a set containing 1,113,396 ratings with 19,639 unique reviewers and 103,687 unique items. The majority of items are rated 5 star.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8653cf",
   "metadata": {
    "id": "3f8653cf",
    "outputId": "1dede61f-4fc4-417e-a37e-72c02b795e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of ratings after filtering:  1113396\n",
      "- Number of unique reviewers:  19639\n",
      "- Number of unique items:  103687\n",
      "- Number of items with 1 rating = 59470\n",
      "- Number of items with 2 rating = 65558\n",
      "- Number of items with 3 rating = 141436\n",
      "- Number of items with 4 rating = 252584\n",
      "- Number of items with 5 rating = 594348\n"
     ]
    }
   ],
   "source": [
    "reviewer_count = df.reviewer_id.value_counts()\n",
    "df = df[df.reviewer_id.isin(reviewer_count[reviewer_count >= 25].index)]\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "del reviewer_count\n",
    "\n",
    "print('- Number of ratings after filtering: ', len(df))\n",
    "print('- Number of unique reviewers: ', df['reviewer_id'].nunique())\n",
    "print('- Number of unique items: ', df['item_id'].nunique())\n",
    "for i in range(1,6):\n",
    "  print('- Number of items with {0} rating = {1}'.format(i, df[df['rating'] == i].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v5b9oDSm-JKG",
   "metadata": {
    "id": "v5b9oDSm-JKG"
   },
   "source": [
    "<font size=\"4\">The top 10 reviewers with the most number of ratings in the filtered set still have over 1,600 ratings/reviews.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674d2c1",
   "metadata": {
    "id": "1674d2c1",
    "outputId": "87834057-ce3a-4883-974a-07ddf04bb71b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewers with highest number of ratings in filtered set:\n",
      "reviewer_id\n",
      "0    3981\n",
      "1    2068\n",
      "2    1997\n",
      "3    1986\n",
      "4    1838\n",
      "5    1811\n",
      "6    1797\n",
      "7    1733\n",
      "8    1706\n",
      "9    1634\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reviewers_top10 = df.groupby('reviewer_id').size().sort_values(ascending=False)[:10]\n",
    "print('Reviewers with highest number of ratings in filtered set:')\n",
    "print(reviewers_top10)\n",
    "\n",
    "del reviewers_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7615ad5-f375-4459-8d3d-9aeca47d4718",
   "metadata": {
    "id": "c7615ad5-f375-4459-8d3d-9aeca47d4718"
   },
   "source": [
    "<font size=\"4\">The top 10 items in the filtered set shows a large reduction with the highest item reducing from 24,554 to 1,136 ratings, while the 10th highest item reducing from 14,174 to 853 ratings.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785a0cc",
   "metadata": {
    "id": "0785a0cc",
    "outputId": "a96cdb28-ffdc-43ae-c938-14cea2f23b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items with highest number of ratings filtered set:\n",
      "item_id\n",
      "8     1136\n",
      "14    1042\n",
      "15    1040\n",
      "13    1040\n",
      "29     964\n",
      "22     903\n",
      "53     895\n",
      "87     870\n",
      "67     860\n",
      "81     853\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "items_top10 = df.groupby('item_id').size().sort_values(ascending=False)[:10]\n",
    "print('Items with highest number of ratings filtered set:')\n",
    "print(items_top10)\n",
    "\n",
    "del items_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95376177-a255-42fa-b946-39814d082957",
   "metadata": {
    "id": "95376177-a255-42fa-b946-39814d082957"
   },
   "source": [
    "## Create Recommendation Systems using Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a09a4f",
   "metadata": {
    "id": "d3a09a4f"
   },
   "source": [
    "<font size=\"4\">The data is loaded using the `Reader` class from a `pandas` dataframe prior to modeling. For the initial training of the models using `surprise`, the default parameters of `BaselineOnly`, `KNNBaseline`, `KNNBasic`, `KNNWithMeans`, `KNNWithZScore`, `CoClustering`, `SVD`, `SVDpp` (an extension of SVD which taking into account implicit ratings), `NMF`, were evaluated using the `cross_validate` method using 3-fold cross validation to determine which algorithm yielded the lowest `RMSE` errors. This revealed that `SVDpp` generated the lowest `RMSE`, but it took the longest to fit the model and test. The default parameters for `SVDpp` uses 20 epochs for fitting the model, so experimenting with less epochs and other model parameters will reduce the runtime and potentially maintain a low `RMSE`. The results from using `KNNBaseline` demonstrate a close loss with a significantly lower runtime, so hyperparameter tuning might allow this to be a better choice, especially given larger sample sizes. <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34f39b",
   "metadata": {
    "id": "7f34f39b",
    "outputId": "594dd537-7211-4af6-e6ad-7fc93ecff80e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating through different algorithms..\n",
      "Finished iterating through different algorithms: 1877.5992422103882\n",
      "Results from testing different algorithms:\n",
      "                 test_rmse     fit_time  test_time\n",
      "Algorithm                                         \n",
      "SVDpp             0.951981  1449.569379  34.628475\n",
      "SVD               0.956978    56.881580   3.054269\n",
      "BaselineOnly      0.958829     0.541074   2.015631\n",
      "KNNBaseline       0.986208    12.493270  27.932690\n",
      "KNNWithMeans      0.996443    12.406364  24.509705\n",
      "KNNWithZScore     1.002136    13.109460  26.066691\n",
      "CoClustering      1.012724    18.731312   2.226075\n",
      "NMF               1.051432    59.292935   2.782387\n",
      "KNNBasic          1.106805    12.031695  23.257696\n",
      "NormalPredictor   1.505521     0.629097   2.384375\n"
     ]
    }
   ],
   "source": [
    "# Set path for results\n",
    "path = r'D:\\AmazonReviews\\Models'\n",
    "os.chdir(path)\n",
    "\n",
    "# Load data using reader\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['reviewer_id', 'item_id', 'rating']], reader)\n",
    "del df\n",
    "\n",
    "# Iterate over all algorithms\n",
    "print('Time for iterating through different algorithms..')\n",
    "search_time_start = time.time()\n",
    "benchmark = []\n",
    "for algorithm in [BaselineOnly(), KNNBaseline(), KNNBasic(), KNNWithMeans(), \n",
    "                  KNNWithZScore(), CoClustering(), SVD(), SVDpp(), NMF(), \n",
    "                  NormalPredictor()]:\n",
    "    # Cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, \n",
    "                             verbose=False, n_jobs=-1)\n",
    "    \n",
    "    # Model results\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]],\n",
    "                               index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "print('Finished iterating through different algorithms:',\n",
    "      time.time() - search_time_start)\n",
    "\n",
    "# Create df with results and save\n",
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    \n",
    "print('Results from testing different algorithms:')\n",
    "print(surprise_results)\n",
    "surprise_results.to_csv('MoviesTV_results_algorithms.csv')\n",
    "del surprise_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed70140-f00a-4e2f-a3b1-18a0a0ee84fb",
   "metadata": {
    "id": "aed70140-f00a-4e2f-a3b1-18a0a0ee84fb"
   },
   "source": [
    "<font size=\"4\"><font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81998dab",
   "metadata": {
    "id": "81998dab"
   },
   "outputs": [],
   "source": [
    "# Set path for loading train/test\n",
    "path = r'D:\\AmazonReviews\\Data'\n",
    "os.chdir(path)\n",
    "\n",
    "# Read train/test sets\n",
    "train = pd.read_csv('train_filtered.csv', sep='|')\n",
    "train.columns = ['item_id', 'reviewer_id', 'rating']\n",
    "\n",
    "test = pd.read_csv('eval_filtered.csv', sep='|')\n",
    "test.columns = ['item_id', 'reviewer_id', 'rating']\n",
    "\n",
    "# Load data using reader\n",
    "train = Dataset.load_from_df(train[['reviewer_id', 'item_id', 'rating']], reader)\n",
    "test = Dataset.load_from_df(test[['reviewer_id', 'item_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f9393",
   "metadata": {
    "id": "e01f9393"
   },
   "source": [
    "### SVDpp with lowest rmse \n",
    "Fit model with default parameters for 3 epochs and examine RMSE on train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfa063",
   "metadata": {
    "id": "5abfa063",
    "outputId": "a5edc369-d190-442d-beb4-d9978117035c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/predict using SVDpp default parameters for 3 epochs:\n",
      "\n",
      "\n",
      "Time for iterating through SVDpp default parameters..\n",
      "Finished iterating through SVDpp default parameters: 259.01811718940735\n",
      "\n",
      "\n",
      "Cross validation results:\n",
      "test_rmse  :  [0.99186233 0.99067176 0.98925811]\n",
      "test_mae  :  [0.75639429 0.75586697 0.75391987]\n",
      "fit_time  :  (212.8136830329895, 213.71945691108704, 214.16111540794373)\n",
      "test_time  :  (34.81285309791565, 35.151495695114136, 34.626320362091064)\n",
      "\n",
      "\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9811\n",
      "0.9811266996736911\n"
     ]
    }
   ],
   "source": [
    "# Set path for results\n",
    "path = r'D:\\AmazonReviews\\Models'\n",
    "os.chdir(path)\n",
    "\n",
    "print('Train/predict using SVDpp default parameters for 3 epochs:')\n",
    "print('\\n')\n",
    "print('Time for iterating through SVDpp default parameters..')\n",
    "search_time_start = time.time()\n",
    "algo = SVDpp(n_epochs=3, random_state=seed_value)\n",
    "cv = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=False, \n",
    "                    n_jobs=-1)\n",
    "print('Finished iterating through SVDpp default parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Cross validation results:')\n",
    "# Iterate over key/value pairs in cv results dict \n",
    "for key, value in cv.items():\n",
    "    print(key, ' : ', value)\n",
    "print('\\n')\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./SVDpp_3epochs_DefaultParamModel_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./SVDpp_3epochs_DefaultParamModel_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a1a92-6027-4040-ad8b-3e9b9f82c83d",
   "metadata": {
    "id": "f14a1a92-6027-4040-ad8b-3e9b9f82c83d"
   },
   "source": [
    "<font size=\"4\">Examine results from predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390fe37",
   "metadata": {
    "id": "1390fe37"
   },
   "outputs": [],
   "source": [
    "def get_Ir(reviewerID):\n",
    "    \"\"\"\n",
    "    Determine the number of items rated by given reviewer\n",
    "    Args: \n",
    "      reviewerID: the id of the reviewer\n",
    "    Returns: \n",
    "      Number of items rated by the reviewer\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(train.ur[train.to_inner_uid(reviewerID)])\n",
    "    except ValueError: \n",
    "        return 0\n",
    "    \n",
    "def get_Ri(itemID):\n",
    "    \"\"\" \n",
    "    Determine number of reviewers that rated given item\n",
    "    Args:\n",
    "      itemID: the id of the item\n",
    "    Returns:\n",
    "     Number of reviewers that have rated the item\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(train.ir[train.to_inner_iid(itemID)])\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be369bf6-aa28-4869-b95c-363af4c731f8",
   "metadata": {
    "id": "be369bf6-aa28-4869-b95c-363af4c731f8"
   },
   "source": [
    "<font size=\"4\"> Make df of prediction results, apply functions and save prediction results<font size>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47659f",
   "metadata": {
    "id": "ab47659f"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details']) \n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)\n",
    "df1.to_csv('predictions_SVDpp_DefaultParamModel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720a881-8050-4a83-923b-d719fa4c25bc",
   "metadata": {
    "id": "a720a881-8050-4a83-923b-d719fa4c25bc"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060956bc",
   "metadata": {
    "id": "060956bc",
    "outputId": "2321b00d-9dde-43d8-f819-9da432b4496d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "2465          1901     286  5.0  5.0  {'was_impossible': False}   81  247  0.0\n",
      "103694        2922     300  5.0  5.0  {'was_impossible': False}   59  190  0.0\n",
      "140212       11094     444  5.0  5.0  {'was_impossible': False}   28  193  0.0\n",
      "196650         198    1488  5.0  5.0  {'was_impossible': False}  284   47  0.0\n",
      "34119         2454    2501  5.0  5.0  {'was_impossible': False}   62   43  0.0\n",
      "14052         3719     151  5.0  5.0  {'was_impossible': False}   51  440  0.0\n",
      "34137         3916    2600  5.0  5.0  {'was_impossible': False}   50   92  0.0\n",
      "159982        1066      14  5.0  5.0  {'was_impossible': False}   97  837  0.0\n",
      "64899         5448     147  5.0  5.0  {'was_impossible': False}   39  223  0.0\n",
      "103569         882    5672  5.0  5.0  {'was_impossible': False}  121   79  0.0\n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v-hKRE5zvWXE",
   "metadata": {
    "id": "v-hKRE5zvWXE"
   },
   "source": [
    "<font size=\"4\"> Find the worst  predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56c751",
   "metadata": {
    "id": "dc56c751",
    "outputId": "b3287684-af53-4b72-9828-2e6bb72e698f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui       est                    details   Iu  \\\n",
      "26621         4844     269  1.0  4.995164  {'was_impossible': False}   38   \n",
      "148629          42     172  1.0  5.000000  {'was_impossible': False}  660   \n",
      "44833         5789     409  1.0  5.000000  {'was_impossible': False}   41   \n",
      "67997         8107     534  1.0  5.000000  {'was_impossible': False}   29   \n",
      "29490          778    2691  1.0  5.000000  {'was_impossible': False}  122   \n",
      "110642        1311     451  1.0  5.000000  {'was_impossible': False}   93   \n",
      "119911        1331    1915  1.0  5.000000  {'was_impossible': False}   95   \n",
      "109341         835    2752  1.0  5.000000  {'was_impossible': False}  116   \n",
      "33420         4933     752  1.0  5.000000  {'was_impossible': False}   43   \n",
      "118018        1666    1834  1.0  5.000000  {'was_impossible': False}   77   \n",
      "\n",
      "         Ui       err  \n",
      "26621   158  3.995164  \n",
      "148629  588  4.000000  \n",
      "44833   243  4.000000  \n",
      "67997   262  4.000000  \n",
      "29490    79  4.000000  \n",
      "110642  461  4.000000  \n",
      "119911   63  4.000000  \n",
      "109341    4  4.000000  \n",
      "33420   209  4.000000  \n",
      "118018   97  4.000000  \n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e6a88",
   "metadata": {
    "id": "052e6a88"
   },
   "source": [
    "#### SVDpp HPO using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff8d45-d32c-49dd-844a-4af888e8819c",
   "metadata": {
    "id": "07ff8d45-d32c-49dd-844a-4af888e8819c"
   },
   "source": [
    "<font size=\"4\">Hyperparameter optimization using `GridSearchCV` was performed to find the best parameters. Since this algorithm is omputationally expensive with gradient descent, 10 epochs was used. A larger number of factors compared to the default `n_factors=20`, The default parameters for `lr_all=0.007` and `reg_all=0.02` were included in the search. <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rHs3NkUpzsVi",
   "metadata": {
    "id": "rHs3NkUpzsVi"
   },
   "source": [
    "<font size=\"4\">Define the parameters for the grid search <font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407255e",
   "metadata": {
    "id": "6407255e",
    "outputId": "a9251f2d-5952-4fdf-a3ec-d2eb74d99c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_epochs': [10],\n",
       " 'n_factors': [30, 40, 50],\n",
       " 'lr_all': [0.0007, 0.007, 0.07],\n",
       " 'reg_all': [0.0002, 0.002, 0.02],\n",
       " 'random_state': [42]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [10],\n",
    "              'n_factors': [30, 40, 50], \n",
    "              'lr_all': [7e-4, 7e-3, 7e-2], \n",
    "              'reg_all': [2e-4, 2e-3, 2e-2],\n",
    "              'random_state': [seed_value]}\n",
    "print('Grid search parameters:')\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1186c41-feca-4e26-a4cf-afcbe5b7de91",
   "metadata": {
    "id": "a1186c41-feca-4e26-a4cf-afcbe5b7de91"
   },
   "source": [
    "<font size=\"4\">Run grid search with `rmse` and `mae` as the metrics. Then use the parameters that resulted in the lowest RMSE on the train/test sets<font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af05ca",
   "metadata": {
    "id": "e8af05ca",
    "outputId": "14ce9b20-3931-4fd0-cc96-68b09cf4dd2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating grid search parameters..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 98.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iterating grid search parameters: 12332.196253061295\n",
      "\n",
      "\n",
      "Lowest RMSE from Grid Search:\n",
      "0.9525513633721562\n",
      "\n",
      "\n",
      "Parameters of Model with lowest RMSE from Grid Search:\n",
      "{'n_epochs': 10, 'n_factors': 30, 'lr_all': 0.007, 'reg_all': 0.02, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed: 205.4min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3,\n",
    "                  joblib_verbose=-1, n_jobs=-1)\n",
    "print('Time for iterating grid search parameters..')\n",
    "search_time_start = time.time()\n",
    "gs.fit(data)\n",
    "print('Finished iterating grid search parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Lowest RMSE from Grid Search:')\n",
    "print(gs.best_score['rmse'])\n",
    "print('\\n')\n",
    "print('Parameters of Model with lowest RMSE from Grid Search:')\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc0bc9",
   "metadata": {
    "id": "c4bc0bc9",
    "outputId": "c6161a69-2b83-4310-e2dc-fd4c55d780ae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVDpp GridSearch HPO Cross Validation Results:\n",
      "    split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
      "5           0.955645          0.950836          0.951173        0.952551   \n",
      "14          0.956360          0.951313          0.951621        0.953098   \n",
      "4           0.956469          0.951755          0.951959        0.953394   \n",
      "23          0.957312          0.952152          0.953361        0.954275   \n",
      "13          0.957878          0.953556          0.953487        0.954974   \n",
      "\n",
      "    std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
      "5        0.002192               1         0.697202         0.694840   \n",
      "14       0.002310               2         0.698210         0.695600   \n",
      "4        0.002176               3         0.694615         0.692085   \n",
      "23       0.002204               4         0.698765         0.696435   \n",
      "13       0.002054               5         0.695999         0.693928   \n",
      "\n",
      "    split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  \\\n",
      "5          0.694414       0.695485      0.001226              4   \n",
      "14         0.695098       0.696303      0.001364              5   \n",
      "4          0.691465       0.692721      0.001362              1   \n",
      "23         0.697008       0.697403      0.000991              8   \n",
      "13         0.693330       0.694419      0.001144              3   \n",
      "\n",
      "    mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
      "5     1760.764067      4.727102       78.318940       2.095161   \n",
      "14    2147.952381      9.731473       78.980110       2.228859   \n",
      "4     1778.924684     10.579680       77.196859       1.908792   \n",
      "23    2554.480703     28.594806       65.637926       5.264038   \n",
      "13    2158.426135     10.905989       80.729247       1.357223   \n",
      "\n",
      "                                               params  param_n_epochs  \\\n",
      "5   {'n_epochs': 10, 'n_factors': 30, 'lr_all': 0....              10   \n",
      "14  {'n_epochs': 10, 'n_factors': 40, 'lr_all': 0....              10   \n",
      "4   {'n_epochs': 10, 'n_factors': 30, 'lr_all': 0....              10   \n",
      "23  {'n_epochs': 10, 'n_factors': 50, 'lr_all': 0....              10   \n",
      "13  {'n_epochs': 10, 'n_factors': 40, 'lr_all': 0....              10   \n",
      "\n",
      "    param_n_factors  param_lr_all  param_reg_all  param_random_state  \n",
      "5                30         0.007          0.020                  42  \n",
      "14               40         0.007          0.020                  42  \n",
      "4                30         0.007          0.002                  42  \n",
      "23               50         0.007          0.020                  42  \n",
      "13               40         0.007          0.002                  42  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save results to df\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df = results_df.sort_values('mean_test_rmse', ascending=True)\n",
    "\n",
    "print('SVDpp GridSearch HPO Cross Validation Results:')\n",
    "print(results_df.head())\n",
    "print('\\n')\n",
    "results_df.to_csv('SVDpp_gridSearch_cvResults.csv', index=False)\n",
    "\n",
    "del results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LgDuVLGmxrAF",
   "metadata": {
    "id": "LgDuVLGmxrAF"
   },
   "source": [
    "<font size=\"4\">Fit and predict on the best model, apply functions and save prediction results <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3976d73",
   "metadata": {
    "id": "b3976d73",
    "outputId": "82287316-f348-4e46-f876-ae438f624e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9466\n",
      "0.9465595720332523\n"
     ]
    }
   ],
   "source": [
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./SVDpp_bestGrid_Model_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./SVDpp_bestGrid_Model_file')\n",
    "  \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)\n",
    "df1.to_csv('predictions_SVDpp_gridSearch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3FeT6esru28R",
   "metadata": {
    "id": "3FeT6esru28R"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf9ceb",
   "metadata": {
    "id": "f5cf9ceb",
    "outputId": "fcd197ae-ac5c-4225-b6d7-b7b2f28ace1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "66148         1115    3391  5.0  5.0  {'was_impossible': False}  101  112  0.0\n",
      "68178        12878    5195  5.0  5.0  {'was_impossible': False}   25   29  0.0\n",
      "68175         3186    9565  5.0  5.0  {'was_impossible': False}   51   28  0.0\n",
      "175864        3773    2453  5.0  5.0  {'was_impossible': False}   47  137  0.0\n",
      "213457        6532     420  5.0  5.0  {'was_impossible': False}   40  185  0.0\n",
      "68171         9096     512  5.0  5.0  {'was_impossible': False}   27  168  0.0\n",
      "68168        13356    2956  5.0  5.0  {'was_impossible': False}   25   75  0.0\n",
      "68158         3830    8075  5.0  5.0  {'was_impossible': False}   47   46  0.0\n",
      "68123         7200    2041  5.0  5.0  {'was_impossible': False}   31   52  0.0\n",
      "68113         7108    7983  5.0  5.0  {'was_impossible': False}   38   24  0.0\n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-yVnvmczvQZE",
   "metadata": {
    "id": "-yVnvmczvQZE"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044a3c7",
   "metadata": {
    "id": "a044a3c7",
    "outputId": "e536cabc-754e-4f52-96c9-0512c80a621d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "110642        1311     451  1.0  5.0  {'was_impossible': False}   93  461  4.0\n",
      "39171         3522     906  1.0  5.0  {'was_impossible': False}   51   46  4.0\n",
      "67997         8107     534  1.0  5.0  {'was_impossible': False}   29  262  4.0\n",
      "12513          804   23913  1.0  5.0  {'was_impossible': False}  117    4  4.0\n",
      "11064        10089    2718  1.0  5.0  {'was_impossible': False}   28   90  4.0\n",
      "132808        4212   11537  1.0  5.0  {'was_impossible': False}   43   35  4.0\n",
      "53552         2548   10674  1.0  5.0  {'was_impossible': False}   68   41  4.0\n",
      "157725       14167    5196  1.0  5.0  {'was_impossible': False}   25   29  4.0\n",
      "80945        18177    2118  1.0  5.0  {'was_impossible': False}   20   61  4.0\n",
      "204198        6386    3565  1.0  5.0  {'was_impossible': False}   32   34  4.0\n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99636793",
   "metadata": {
    "id": "99636793"
   },
   "source": [
    "#### SVDpp HPO using Grid Search - 20 Epochs More Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O_36oR5oztVA",
   "metadata": {
    "id": "O_36oR5oztVA"
   },
   "source": [
    "<font size=\"4\">Define the parameters for the grid search <font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a939f",
   "metadata": {
    "id": "459a939f",
    "outputId": "a51081de-4cff-48c6-d4fa-25fa65b5aaac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_epochs': [20],\n",
       " 'n_factors': [10, 20, 30, 40, 50],\n",
       " 'lr_all': [7e-06, 7e-05, 0.0007, 0.007, 0.07],\n",
       " 'reg_all': [0.0002, 0.002, 0.02, 0.2, 2.0],\n",
       " 'random_state': [42]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [20],\n",
    "              'n_factors': [10, 20, 30, 40, 50], \n",
    "              'lr_all': [7e-6, 7e-5, 7e-4, 7e-3, 7e-2], \n",
    "              'reg_all': [2e-4, 2e-3, 2e-2, 2e-1, 2e-0],\n",
    "              'random_state': [seed_value]}\n",
    "print('Grid search parameters:')\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lUfffAr2zPAj",
   "metadata": {
    "id": "lUfffAr2zPAj"
   },
   "source": [
    "<font size=\"4\">Run grid search with `rmse` and `mae` as the metrics. Then use the parameters that resulted in the lowest RMSE on the train/test sets<font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af7655",
   "metadata": {
    "id": "22af7655",
    "outputId": "bc528061-c8a0-4aea-bf9e-71a0ed6ade5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating grid search parameters..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 103.0min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed: 791.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iterating grid search parameters: 82490.94835019112\n",
      "\n",
      "\n",
      "Lowest RMSE from Grid Search:\n",
      "0.9487615218367708\n",
      "\n",
      "\n",
      "Parameters of Model with lowest RMSE from Grid Search:\n",
      "{'n_epochs': 20, 'n_factors': 10, 'lr_all': 0.007, 'reg_all': 0.02, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 375 out of 375 | elapsed: 1374.8min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3,\n",
    "                  joblib_verbose=-1, n_jobs=-1)\n",
    "print('Time for iterating grid search parameters..')\n",
    "search_time_start = time.time()\n",
    "gs.fit(data)\n",
    "print('Finished iterating grid search parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Lowest RMSE from Grid Search:')\n",
    "print(gs.best_score['rmse'])\n",
    "print('\\n')\n",
    "print('Parameters of Model with lowest RMSE from Grid Search:')\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bee6e",
   "metadata": {
    "id": "be3bee6e",
    "outputId": "d9b13791-08c6-4131-887c-db22f60d5ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVDpp GridSearch HPO Cross Validation Results:\n",
      "    split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
      "17          0.949363          0.950721          0.946200        0.948762   \n",
      "18          0.951589          0.950517          0.947567        0.949891   \n",
      "43          0.951702          0.950655          0.947704        0.950020   \n",
      "68          0.951936          0.950781          0.947783        0.950167   \n",
      "93          0.952030          0.950867          0.947989        0.950295   \n",
      "\n",
      "    std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
      "17       0.001894               1         0.680528         0.681833   \n",
      "18       0.001701               2         0.699633         0.698991   \n",
      "43       0.001693               3         0.699909         0.699289   \n",
      "68       0.001750               4         0.700300         0.699534   \n",
      "93       0.001699               5         0.700566         0.699855   \n",
      "\n",
      "    split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  \\\n",
      "17         0.677630       0.679997      0.001757              1   \n",
      "18         0.695998       0.698207      0.001584             13   \n",
      "43         0.696320       0.698506      0.001566             14   \n",
      "68         0.696594       0.698810      0.001597             15   \n",
      "93         0.696950       0.699124      0.001564             16   \n",
      "\n",
      "    mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
      "17    1980.939517     15.863968       77.221512       1.535108   \n",
      "18    1982.354941      6.644640       77.657765       0.285184   \n",
      "43    2621.355183     12.571746       72.014355       0.508856   \n",
      "68    3399.626885     15.252084       70.916236       0.894807   \n",
      "93    4074.821517     15.447206       72.847546       1.333736   \n",
      "\n",
      "                                               params  param_n_epochs  \\\n",
      "17  {'n_epochs': 20, 'n_factors': 10, 'lr_all': 0....              20   \n",
      "18  {'n_epochs': 20, 'n_factors': 10, 'lr_all': 0....              20   \n",
      "43  {'n_epochs': 20, 'n_factors': 20, 'lr_all': 0....              20   \n",
      "68  {'n_epochs': 20, 'n_factors': 30, 'lr_all': 0....              20   \n",
      "93  {'n_epochs': 20, 'n_factors': 40, 'lr_all': 0....              20   \n",
      "\n",
      "    param_n_factors  param_lr_all  param_reg_all  param_random_state  \n",
      "17               10         0.007           0.02                  42  \n",
      "18               10         0.007           0.20                  42  \n",
      "43               20         0.007           0.20                  42  \n",
      "68               30         0.007           0.20                  42  \n",
      "93               40         0.007           0.20                  42  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save results to df\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df = results_df.sort_values('mean_test_rmse', ascending=True)\n",
    "\n",
    "print('SVDpp GridSearch HPO Cross Validation Results:')\n",
    "print(results_df.head())\n",
    "print('\\n')\n",
    "results_df.to_csv('SVDpp_gridSearch_cvResults_moreParams.csv', index=False)\n",
    "\n",
    "del results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hx5KauoNyVnz",
   "metadata": {
    "id": "hx5KauoNyVnz"
   },
   "source": [
    "<font size=\"4\">Fit and predict on the best model, apply functions and save prediction results <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045022f8",
   "metadata": {
    "id": "045022f8",
    "outputId": "8bc6621f-358b-4981-abbb-18f7f09129c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9439\n",
      "0.9438520213385112\n"
     ]
    }
   ],
   "source": [
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./SVDpp_bestGrid_Model_moreParams_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./SVDpp_bestGrid_Model_file')\n",
    "    \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)\n",
    "df1.to_csv('predictions_SVDpp_gridSearch_moreParams.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wl5hFIZ2ux8o",
   "metadata": {
    "id": "wl5hFIZ2ux8o"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b548b",
   "metadata": {
    "id": "ef8b548b",
    "outputId": "1abaa252-8ba2-4ad7-824c-4f6e684175e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "199772        5707   12824  5.0  5.0  {'was_impossible': False}   42   27  0.0\n",
      "183867        4328     807  5.0  5.0  {'was_impossible': False}   46  196  0.0\n",
      "83935          865    2576  5.0  5.0  {'was_impossible': False}  113   65  0.0\n",
      "83923         5238    1240  5.0  5.0  {'was_impossible': False}   48   63  0.0\n",
      "166321       12530    1752  5.0  5.0  {'was_impossible': False}   21   81  0.0\n",
      "14868         1166    9580  5.0  5.0  {'was_impossible': False}  101   24  0.0\n",
      "122028         892    3886  5.0  5.0  {'was_impossible': False}  115   43  0.0\n",
      "33111         2022      45  5.0  5.0  {'was_impossible': False}   75  635  0.0\n",
      "33094         1772   38840  5.0  5.0  {'was_impossible': False}   73    3  0.0\n",
      "122030       14191   16620  5.0  5.0  {'was_impossible': False}   20   15  0.0\n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yR4zQ7Z6vtPd",
   "metadata": {
    "id": "yR4zQ7Z6vtPd"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2ce31",
   "metadata": {
    "id": "65b2ce31",
    "outputId": "80289bec-d0af-46ba-b4de-ea77a0471a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "98501        10283    5532  1.0  5.0  {'was_impossible': False}   27   34  4.0\n",
      "12513          804   23913  1.0  5.0  {'was_impossible': False}  117    4  4.0\n",
      "157725       14167    5196  1.0  5.0  {'was_impossible': False}   25   29  4.0\n",
      "11064        10089    2718  1.0  5.0  {'was_impossible': False}   28   90  4.0\n",
      "140176          38     109  1.0  5.0  {'was_impossible': False}  701  556  4.0\n",
      "67222        12174    1319  1.0  5.0  {'was_impossible': False}   26   92  4.0\n",
      "13116         3284    3483  1.0  5.0  {'was_impossible': False}   54  101  4.0\n",
      "147671         835   96950  1.0  5.0  {'was_impossible': False}  116    1  4.0\n",
      "119911        1331    1915  1.0  5.0  {'was_impossible': False}   95   63  4.0\n",
      "192547        5214     139  1.0  5.0  {'was_impossible': False}   41  535  4.0\n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45c10d",
   "metadata": {
    "id": "ce45c10d"
   },
   "source": [
    "#### SVDpp HPO using Grid Search - 20 Epochs More Parameters Less Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v3MIgnvJzuM-",
   "metadata": {
    "id": "v3MIgnvJzuM-"
   },
   "source": [
    "<font size=\"4\">Define the parameters for the grid search <font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece4068",
   "metadata": {
    "id": "0ece4068",
    "outputId": "aacb9e7f-b788-4a35-8247-aa31ced9213c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_epochs': [20],\n",
       " 'n_factors': [5, 10, 15],\n",
       " 'lr_all': [0.0007, 0.007, 0.07],\n",
       " 'reg_all': [0.07, 0.05, 0.02, 0.7],\n",
       " 'random_state': [42]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [20],\n",
    "              'n_factors': [5, 10, 15], \n",
    "              'lr_all': [7e-4, 7e-3, 7e-2], \n",
    "              'reg_all': [7e-2, 5e-2, 2e-2, 7e-1],\n",
    "              'random_state': [seed_value]}\n",
    "print('Grid search parameters:')\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hissKx7czQwF",
   "metadata": {
    "id": "hissKx7czQwF"
   },
   "source": [
    "<font size=\"4\">Run grid search with `rmse` and `mae` as the metrics. Then use the parameters that resulted in the lowest RMSE on the train/test sets<font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5980c8",
   "metadata": {
    "id": "5a5980c8",
    "outputId": "aa9ea600-2d06-4845-82fb-c11fa0308f09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating grid search parameters..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 87.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iterating grid search parameters: 13742.905663013458\n",
      "\n",
      "\n",
      "Lowest RMSE from Grid Search:\n",
      "0.9454947143378393\n",
      "\n",
      "\n",
      "Parameters of Model with lowest RMSE from Grid Search:\n",
      "{'n_epochs': 20, 'n_factors': 5, 'lr_all': 0.007, 'reg_all': 0.05, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 229.0min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3,\n",
    "                  joblib_verbose=-1, n_jobs=-1)\n",
    "print('Time for iterating grid search parameters..')\n",
    "search_time_start = time.time()\n",
    "gs.fit(data)\n",
    "print('Finished iterating grid search parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Lowest RMSE from Grid Search:')\n",
    "print(gs.best_score['rmse'])\n",
    "print('\\n')\n",
    "print('Parameters of Model with lowest RMSE from Grid Search:')\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ff3a1",
   "metadata": {
    "id": "267ff3a1",
    "outputId": "72ab07f1-b171-45c7-c256-b3566f578f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVDpp GridSearch HPO Cross Validation Results:\n",
      "    split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
      "5           0.948897          0.943507          0.944079        0.945495   \n",
      "4           0.948880          0.943676          0.944297        0.945618   \n",
      "16          0.948938          0.943844          0.944304        0.945695   \n",
      "28          0.948962          0.943712          0.944634        0.945769   \n",
      "17          0.949299          0.943932          0.944247        0.945826   \n",
      "\n",
      "    std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
      "5        0.002417               1         0.684832         0.682043   \n",
      "4        0.002321               2         0.686716         0.684125   \n",
      "16       0.002301               3         0.686884         0.684269   \n",
      "28       0.002289               4         0.686872         0.684129   \n",
      "17       0.002459               5         0.685130         0.682168   \n",
      "\n",
      "    split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  \\\n",
      "5          0.681793       0.682889      0.001377              4   \n",
      "4          0.683896       0.684913      0.001279              7   \n",
      "16         0.683806       0.684986      0.001355              8   \n",
      "28         0.684206       0.685069      0.001276              9   \n",
      "17         0.681556       0.682951      0.001561              5   \n",
      "\n",
      "    mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
      "5     1538.214133      9.366337       74.756616       0.963164   \n",
      "4     1544.355476      3.865669       74.432318       1.427925   \n",
      "16    1910.758532      9.697008       73.113926       0.483212   \n",
      "28    2274.356767     17.361908       70.215237       1.224627   \n",
      "17    1896.146014      8.418769       71.352642       0.601564   \n",
      "\n",
      "                                               params  param_n_epochs  \\\n",
      "5   {'n_epochs': 20, 'n_factors': 5, 'lr_all': 0.0...              20   \n",
      "4   {'n_epochs': 20, 'n_factors': 5, 'lr_all': 0.0...              20   \n",
      "16  {'n_epochs': 20, 'n_factors': 10, 'lr_all': 0....              20   \n",
      "28  {'n_epochs': 20, 'n_factors': 15, 'lr_all': 0....              20   \n",
      "17  {'n_epochs': 20, 'n_factors': 10, 'lr_all': 0....              20   \n",
      "\n",
      "    param_n_factors  param_lr_all  param_reg_all  param_random_state  \n",
      "5                 5         0.007           0.05                  42  \n",
      "4                 5         0.007           0.07                  42  \n",
      "16               10         0.007           0.07                  42  \n",
      "28               15         0.007           0.07                  42  \n",
      "17               10         0.007           0.05                  42  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save results to df\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df = results_df.sort_values('mean_test_rmse', ascending=True)\n",
    "\n",
    "print('SVDpp GridSearch HPO Cross Validation Results:')\n",
    "print(results_df.head())\n",
    "print('\\n')\n",
    "results_df.to_csv('SVDpp_gridSearch_cvResults_moreParamsLessFactors.csv', index=False)\n",
    "\n",
    "del results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o9wRkwACybaS",
   "metadata": {
    "id": "o9wRkwACybaS"
   },
   "source": [
    "<font size=\"4\">Fit and predict on the best model, apply functions and save prediction results <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de63bce",
   "metadata": {
    "id": "4de63bce",
    "outputId": "3ac7a013-bffc-4a87-bb02-6498966bdccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9405\n",
      "0.940543273193018\n"
     ]
    }
   ],
   "source": [
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./SVDpp_bestGrid_Model_moreParams_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./SVDpp_bestGrid_Model_file')\n",
    "    \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)\n",
    "df1.to_csv('predictions_SVDpp_gridSearch_moreParamsLessFactors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6uQNjoLu5Ua",
   "metadata": {
    "id": "b6uQNjoLu5Ua"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c524c5",
   "metadata": {
    "id": "94c524c5",
    "outputId": "fd3b9d62-b248-48b6-f111-40d8d67dcf0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details    Iu   Ui  \\\n",
      "194083        3613    1417  5.0  5.0  {'was_impossible': False}    50   80   \n",
      "192688        6628    2512  5.0  5.0  {'was_impossible': False}    37   24   \n",
      "42659         1066   23696  5.0  5.0  {'was_impossible': False}    97   19   \n",
      "104939        1505    7867  5.0  5.0  {'was_impossible': False}    82   19   \n",
      "149062         602    9291  5.0  5.0  {'was_impossible': False}   141   22   \n",
      "42666         3437    4268  5.0  5.0  {'was_impossible': False}    54   43   \n",
      "104935          13   20848  5.0  5.0  {'was_impossible': False}  1171   12   \n",
      "192690        3709    8889  5.0  5.0  {'was_impossible': False}    51   12   \n",
      "213285        9615    1405  5.0  5.0  {'was_impossible': False}    31   69   \n",
      "42680           13    2069  5.0  5.0  {'was_impossible': False}  1171  157   \n",
      "\n",
      "        err  \n",
      "194083  0.0  \n",
      "192688  0.0  \n",
      "42659   0.0  \n",
      "104939  0.0  \n",
      "149062  0.0  \n",
      "42666   0.0  \n",
      "104935  0.0  \n",
      "192690  0.0  \n",
      "213285  0.0  \n",
      "42680   0.0  \n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EMPySuYQvv4g",
   "metadata": {
    "id": "EMPySuYQvv4g"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17914c6",
   "metadata": {
    "id": "d17914c6",
    "outputId": "a043b7a9-c873-413c-ab00-e550a19e122b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "13116         3284    3483  1.0  5.0  {'was_impossible': False}   54  101  4.0\n",
      "220688       16290    2647  1.0  5.0  {'was_impossible': False}   22   37  4.0\n",
      "22368        11682    2998  1.0  5.0  {'was_impossible': False}   24   84  4.0\n",
      "21561           38   34867  5.0  1.0  {'was_impossible': False}  701   12  4.0\n",
      "12513          804   23913  1.0  5.0  {'was_impossible': False}  117    4  4.0\n",
      "147671         835   96950  1.0  5.0  {'was_impossible': False}  116    1  4.0\n",
      "44833         5789     409  1.0  5.0  {'was_impossible': False}   41  243  4.0\n",
      "190931        8522    1795  1.0  5.0  {'was_impossible': False}   35  126  4.0\n",
      "118238        8688   12360  1.0  5.0  {'was_impossible': False}   30   13  4.0\n",
      "147695        9038    5276  1.0  5.0  {'was_impossible': False}   31   20  4.0\n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e1b45",
   "metadata": {
    "id": "0b5e1b45"
   },
   "source": [
    "### SVD \n",
    "Fit model with default parameters for 3 epochs, examine RMSE on train/test sets and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae1975",
   "metadata": {
    "id": "ebae1975",
    "outputId": "78ed1f27-d10b-4909-ccaf-69c27cbbad22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/predict using SVD default parameters for 3 epochs:\n",
      "\n",
      "\n",
      "Time for iterating through SVD default parameters..\n",
      "Finished iterating through SVD default parameters: 21.718221426010132\n",
      "\n",
      "\n",
      "Cross validation results:\n",
      "test_rmse  :  [1.01170944 1.01306478 1.00997506]\n",
      "test_mae  :  [0.77944209 0.78081871 0.77882791]\n",
      "fit_time  :  (9.072836875915527, 8.729201793670654, 8.824720859527588)\n",
      "test_time  :  (2.9705753326416016, 3.0572056770324707, 2.9552011489868164)\n",
      "\n",
      "\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9995\n",
      "0.9995495492030135\n"
     ]
    }
   ],
   "source": [
    "print('Train/predict using SVD default parameters for 3 epochs:')\n",
    "print('\\n')\n",
    "print('Time for iterating through SVD default parameters..')\n",
    "search_time_start = time.time()\n",
    "algo = SVD(n_epochs=3, random_state=seed_value)\n",
    "cv = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=False, \n",
    "                    n_jobs=-1)\n",
    "print('Finished iterating through SVD default parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Cross validation results:')\n",
    "# Iterate over key/value pairs in cv results dict \n",
    "for key, value in cv.items():\n",
    "    print(key, ' : ', value)\n",
    "print('\\n')\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./SVD_3epochs_DefaultParamModel_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./SVD_3epochs_DefaultParamModel_file')\n",
    " \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)   \n",
    "df1.to_csv('predictions_SVD_DefaultParamModel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1h4ZQsfGv0rv",
   "metadata": {
    "id": "1h4ZQsfGv0rv"
   },
   "source": [
    "<font size=\"4\"> Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9814ed1",
   "metadata": {
    "id": "a9814ed1",
    "outputId": "f75fc8eb-68cf-498c-ff4f-256fffb67ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details    Iu   Ui  \\\n",
      "0             4911       0  5.0  5.0  {'was_impossible': False}    41  334   \n",
      "163930        1279    1286  5.0  5.0  {'was_impossible': False}    92  102   \n",
      "210635          55     959  5.0  5.0  {'was_impossible': False}   605  186   \n",
      "21967           10    1683  5.0  5.0  {'was_impossible': False}  1262  122   \n",
      "195113         120   11155  5.0  5.0  {'was_impossible': False}   392   15   \n",
      "2540          1761    4244  5.0  5.0  {'was_impossible': False}    76   61   \n",
      "163781         313    1893  5.0  5.0  {'was_impossible': False}   216   71   \n",
      "116666         192     407  5.0  5.0  {'was_impossible': False}   286  258   \n",
      "54574          142    1238  5.0  5.0  {'was_impossible': False}   336  212   \n",
      "163763        8633     526  5.0  5.0  {'was_impossible': False}    31  186   \n",
      "\n",
      "        err  \n",
      "0       0.0  \n",
      "163930  0.0  \n",
      "210635  0.0  \n",
      "21967   0.0  \n",
      "195113  0.0  \n",
      "2540    0.0  \n",
      "163781  0.0  \n",
      "116666  0.0  \n",
      "54574   0.0  \n",
      "163763  0.0  \n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2Y7No1AHvycl",
   "metadata": {
    "id": "2Y7No1AHvycl"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9fe93",
   "metadata": {
    "id": "b6c9fe93",
    "outputId": "5c3f279f-05cb-4e3d-e79e-a116daf1445b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui       est                    details    Iu  \\\n",
      "217222         246      92  1.0  4.974257  {'was_impossible': False}   248   \n",
      "21188          291    3674  1.0  4.989281  {'was_impossible': False}   224   \n",
      "83087        17415    1672  1.0  5.000000  {'was_impossible': False}    21   \n",
      "185192          10     833  1.0  5.000000  {'was_impossible': False}  1262   \n",
      "98948         3522     906  1.0  5.000000  {'was_impossible': False}    55   \n",
      "184013         439    2453  1.0  5.000000  {'was_impossible': False}   175   \n",
      "201875        3590     608  1.0  5.000000  {'was_impossible': False}    53   \n",
      "71015         4132    1558  1.0  5.000000  {'was_impossible': False}    48   \n",
      "135268          10     536  1.0  5.000000  {'was_impossible': False}  1262   \n",
      "17450          243    3035  5.0  1.000000  {'was_impossible': False}   261   \n",
      "\n",
      "         Ui       err  \n",
      "217222  151  3.974257  \n",
      "21188    92  3.989281  \n",
      "83087   169  4.000000  \n",
      "185192  187  4.000000  \n",
      "98948    52  4.000000  \n",
      "184013  131  4.000000  \n",
      "201875  248  4.000000  \n",
      "71015   152  4.000000  \n",
      "135268  335  4.000000  \n",
      "17450   104  4.000000  \n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0449d",
   "metadata": {
    "id": "7cd0449d"
   },
   "source": [
    "#### SVD HPO using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Wm3B1bPzvmY",
   "metadata": {
    "id": "1Wm3B1bPzvmY"
   },
   "source": [
    "<font size=\"4\">Define the parameters for the grid search <font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe74ba",
   "metadata": {
    "id": "6ffe74ba",
    "outputId": "5a7a4c81-8e4a-4111-ba85-287b1079edc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD HPO Grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_epochs': [30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
       " 'n_factors': [20, 25, 30, 35, 40, 45, 50],\n",
       " 'lr_all': [0.002, 0.003, 0.004, 0.005, 0.006, 0.007],\n",
       " 'reg_all': [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04],\n",
       " 'random_state': [42]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [30, 35, 40, 45, 50, 55, 60, 65, 70], \n",
    "              'n_factors': [20, 25, 30, 35, 40 ,45 , 50], \n",
    "              'lr_all': [0.002, 0.003, 0.004, 0.005, 0.006, 0.007], \n",
    "              'reg_all': [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04],\n",
    "              'random_state': [seed_value]}\n",
    "print('SVD HPO Grid search parameters:')\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eNStDwrzR-q",
   "metadata": {
    "id": "1eNStDwrzR-q"
   },
   "source": [
    "<font size=\"4\">Run grid search with `rmse` and `mae` as the metrics. Then use the parameters that resulted in the lowest RMSE on the train/test sets<font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf384025",
   "metadata": {
    "id": "bf384025",
    "outputId": "220310f9-87c7-42f5-83bd-ac7c04c4ba3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating grid search parameters..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed: 48.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed: 90.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 153.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2560 tasks      | elapsed: 238.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3496 tasks      | elapsed: 350.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4576 tasks      | elapsed: 501.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5800 tasks      | elapsed: 687.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iterating grid search parameters: 51872.37151479721\n",
      "\n",
      "\n",
      "Lowest RMSE from Grid Search:\n",
      "0.9470577657248332\n",
      "\n",
      "\n",
      "Parameters of Model with lowest RMSE from Grid Search:\n",
      "{'n_epochs': 65, 'n_factors': 20, 'lr_all': 0.002, 'reg_all': 0.04, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 6804 out of 6804 | elapsed: 864.5min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3,\n",
    "                  joblib_verbose=-1, n_jobs=-1)\n",
    "print('Time for iterating grid search parameters..')\n",
    "search_time_start = time.time()\n",
    "gs.fit(data)\n",
    "print('Finished iterating grid search parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Lowest RMSE from Grid Search:')\n",
    "print(gs.best_score['rmse'])\n",
    "print('\\n')\n",
    "print('Parameters of Model with lowest RMSE from Grid Search:')\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406e74f",
   "metadata": {
    "id": "7406e74f",
    "outputId": "12c528e7-26f2-42a1-dca9-e93ec82e19ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD GridSearch HPO Cross Validation Results:\n",
      "      split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
      "1769          0.947837          0.947292          0.946044        0.947058   \n",
      "515           0.947919          0.947282          0.946094        0.947098   \n",
      "1517          0.947917          0.947291          0.946087        0.947098   \n",
      "767           0.947869          0.947354          0.946098        0.947107   \n",
      "17            0.947931          0.947284          0.946113        0.947109   \n",
      "\n",
      "      std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
      "1769       0.000751               1         0.684882         0.684427   \n",
      "515        0.000756               2         0.685845         0.685306   \n",
      "1517       0.000760               3         0.685833         0.685298   \n",
      "767        0.000744               4         0.684506         0.684084   \n",
      "17         0.000752               5         0.685866         0.685321   \n",
      "\n",
      "      split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  \\\n",
      "1769         0.683501       0.684270      0.000575             83   \n",
      "515          0.684445       0.685199      0.000576            168   \n",
      "1517         0.684431       0.685187      0.000578            164   \n",
      "767          0.683143       0.683911      0.000570             49   \n",
      "17           0.684465       0.685217      0.000577            172   \n",
      "\n",
      "      mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
      "1769     110.694426      0.793158        5.775399       0.235709   \n",
      "515       73.020183      0.826249        6.204501       0.493265   \n",
      "1517     105.295258      0.178649        5.506686       0.242048   \n",
      "767       78.236890      0.808342        5.835091       0.203345   \n",
      "17        55.468125      0.798048        5.672714       0.187081   \n",
      "\n",
      "                                                 params  param_n_epochs  \\\n",
      "1769  {'n_epochs': 65, 'n_factors': 20, 'lr_all': 0....              65   \n",
      "515   {'n_epochs': 40, 'n_factors': 20, 'lr_all': 0....              40   \n",
      "1517  {'n_epochs': 60, 'n_factors': 20, 'lr_all': 0....              60   \n",
      "767   {'n_epochs': 45, 'n_factors': 20, 'lr_all': 0....              45   \n",
      "17    {'n_epochs': 30, 'n_factors': 20, 'lr_all': 0....              30   \n",
      "\n",
      "      param_n_factors  param_lr_all  param_reg_all  param_random_state  \n",
      "1769               20         0.002           0.04                  42  \n",
      "515                20         0.003           0.04                  42  \n",
      "1517               20         0.002           0.04                  42  \n",
      "767                20         0.003           0.04                  42  \n",
      "17                 20         0.004           0.04                  42  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save results to df\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df = results_df.sort_values('mean_test_rmse', ascending=True)\n",
    "print('SVD GridSearch HPO Cross Validation Results:')\n",
    "print(results_df.head())\n",
    "print('\\n')\n",
    "results_df.to_csv('SVD_gridSearch_cvResults.csv', index=False)\n",
    "\n",
    "del results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MKxvEV4Tyns-",
   "metadata": {
    "id": "MKxvEV4Tyns-"
   },
   "source": [
    "<font size=\"4\">Fit and predict on the best model, apply functions and save prediction results <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a436e9",
   "metadata": {
    "id": "95a436e9",
    "outputId": "7607e75f-7bc9-4a9c-c061-b4499914ea11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9426\n",
      "0.9426279412758342\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "print('\\n')\n",
    "dump.dump('./SVD_bestGrid_Model_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./SVD_bestGrid_Model_file')\n",
    "\n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)     \n",
    "df1.to_csv('predictions_SVD_gridSearch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5yo9YZBu9Y0",
   "metadata": {
    "id": "e5yo9YZBu9Y0"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ac45d",
   "metadata": {
    "id": "309ac45d",
    "outputId": "7d9a2875-e908-4764-a041-e9d8ed1ce1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "176329       16449     806  5.0  5.0  {'was_impossible': False}   18  206  0.0\n",
      "13930         1410    1456  5.0  5.0  {'was_impossible': False}   84  122  0.0\n",
      "38632        11133   21418  5.0  5.0  {'was_impossible': False}   27   15  0.0\n",
      "197661        4184    6502  5.0  5.0  {'was_impossible': False}   47   23  0.0\n",
      "38643         4880     362  5.0  5.0  {'was_impossible': False}   44  336  0.0\n",
      "97976        10433     577  5.0  5.0  {'was_impossible': False}   25  245  0.0\n",
      "97971        14696     435  5.0  5.0  {'was_impossible': False}   23  188  0.0\n",
      "38631         3128   33032  5.0  5.0  {'was_impossible': False}   56    6  0.0\n",
      "97969          192     918  5.0  5.0  {'was_impossible': False}  293  154  0.0\n",
      "197652         835   22792  5.0  5.0  {'was_impossible': False}  131   14  0.0\n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LGBC_bYSwMUG",
   "metadata": {
    "id": "LGBC_bYSwMUG"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0aaf4",
   "metadata": {
    "id": "59a0aaf4",
    "outputId": "7cacf0f9-d266-4b43-dfc1-6e673054dac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "12813         6703      22  1.0  5.0  {'was_impossible': False}   36  739  4.0\n",
      "114206        1053    4884  1.0  5.0  {'was_impossible': False}  109   25  4.0\n",
      "113120        6928   22390  1.0  5.0  {'was_impossible': False}   34   11  4.0\n",
      "77728         1563   23406  1.0  5.0  {'was_impossible': False}   85   11  4.0\n",
      "80302          705      50  1.0  5.0  {'was_impossible': False}  133  646  4.0\n",
      "57297        18154    1821  1.0  5.0  {'was_impossible': False}   21   47  4.0\n",
      "121154        2098   45548  1.0  5.0  {'was_impossible': False}   70    5  4.0\n",
      "99084        12373    4451  1.0  5.0  {'was_impossible': False}   24   39  4.0\n",
      "907           5443   24721  1.0  5.0  {'was_impossible': False}   40    4  4.0\n",
      "221274        5108    1178  1.0  5.0  {'was_impossible': False}   42  152  4.0\n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del data, train, test, predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d605dd",
   "metadata": {
    "id": "c7d605dd"
   },
   "source": [
    "### BaselineOnly\n",
    "Fit model with default parameters for 3 epochs using `method='als'` and examine RMSE on train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a67d3c",
   "metadata": {
    "id": "95a67d3c",
    "outputId": "af191a99-ce47-4b74-877a-e017b844516b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/predict using Baseline default parameters with Alternating Least Squares for 3 epochs:\n",
      "\n",
      "\n",
      "Baselines estimates configuration:\n",
      "{'method': 'als', 'n_epochs': 3}\n",
      "\n",
      "\n",
      "Model parameters:\n",
      "<surprise.prediction_algorithms.baseline_only.BaselineOnly object at 0x000002F2AB988C40>\n"
     ]
    }
   ],
   "source": [
    "print('Train/predict using Baseline default parameters with Alternating Least Squares for 3 epochs:')\n",
    "print('\\n')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 3}\n",
    "print('Baselines estimates configuration:')\n",
    "print(bsl_options)\n",
    "print('\\n')\n",
    "print('Model parameters:')\n",
    "print(BaselineOnly(bsl_options=bsl_options)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aH9aNHpE6oCM",
   "metadata": {
    "id": "aH9aNHpE6oCM"
   },
   "source": [
    "<font size=\"4\">Cross validation, Fit and predict on best model with the lowest rmse, apply functions and save prediction results  <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724ca1c",
   "metadata": {
    "id": "d724ca1c",
    "outputId": "7bbf3058-a9fc-4f76-c045-413188e81484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating through Baseline default parameters epochs=3 using ALS..\n",
      "Finished iterating through Baseline default parameters epochs=3 using ALS: 13.459791421890259\n",
      "\n",
      "\n",
      "Cross validation results:\n",
      "test_rmse  :  [0.96003615 0.95827913 0.95906949]\n",
      "test_mae  :  [0.7179837  0.71734625 0.7175912 ]\n",
      "fit_time  :  (0.3123772144317627, 0.36087560653686523, 0.28015828132629395)\n",
      "test_time  :  (2.41690731048584, 2.252049207687378, 2.211479425430298)\n",
      "Estimating biases using als...\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9504\n",
      "0.9504451345236158\n"
     ]
    }
   ],
   "source": [
    "print('Time for iterating through Baseline default parameters epochs=3 using ALS..')\n",
    "search_time_start = time.time()\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "cv = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=False, \n",
    "                    n_jobs=-1)\n",
    "print('Finished iterating through Baseline default parameters epochs=3 using ALS:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Cross validation results:')\n",
    "# Iterate over key/value pairs in cv results dict \n",
    "for key, value in cv.items():\n",
    "    print(key, ' : ', value)\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./Baseline_3epochs_DefaultParamModel_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./Baseline_3epochs_DefaultParamModel_file')\n",
    " \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)  \n",
    "df1.to_csv('predictions_Baseline_DefaultParamModel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0PkozbG6fhK",
   "metadata": {
    "id": "f0PkozbG6fhK"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c014563",
   "metadata": {
    "id": "7c014563",
    "outputId": "a5dcc403-b741-4f6e-d661-6d1af2cd2feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details    Iu   Ui  \\\n",
      "140170        5718     164  5.0  5.0  {'was_impossible': False}    38  343   \n",
      "118833        8919     357  5.0  5.0  {'was_impossible': False}    32  273   \n",
      "13622         6881     738  5.0  5.0  {'was_impossible': False}    33  279   \n",
      "209389        5673    1597  5.0  5.0  {'was_impossible': False}    38  143   \n",
      "59221          204     396  5.0  5.0  {'was_impossible': False}   276  324   \n",
      "114384          10    3429  5.0  5.0  {'was_impossible': False}  1297   51   \n",
      "165059       16405    5977  5.0  5.0  {'was_impossible': False}    20   46   \n",
      "132724         139   39056  5.0  5.0  {'was_impossible': False}   326    7   \n",
      "209394        5069    6451  5.0  5.0  {'was_impossible': False}    42   24   \n",
      "92324         1992   12968  5.0  5.0  {'was_impossible': False}    68   25   \n",
      "\n",
      "        err  \n",
      "140170  0.0  \n",
      "118833  0.0  \n",
      "13622   0.0  \n",
      "209389  0.0  \n",
      "59221   0.0  \n",
      "114384  0.0  \n",
      "165059  0.0  \n",
      "132724  0.0  \n",
      "209394  0.0  \n",
      "92324   0.0  \n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WkZjFj-56g0r",
   "metadata": {
    "id": "WkZjFj-56g0r"
   },
   "source": [
    "<font size=\"4\">Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cec6d0",
   "metadata": {
    "id": "c4cec6d0",
    "outputId": "5277f38d-882a-4ab4-cddf-ad1b2498c411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details    Iu   Ui  \\\n",
      "35996         1955   25056  1.0  5.0  {'was_impossible': False}    71   14   \n",
      "219408         969     798  1.0  5.0  {'was_impossible': False}   107  212   \n",
      "39115         1331    1915  1.0  5.0  {'was_impossible': False}    94   57   \n",
      "22671           10    6563  1.0  5.0  {'was_impossible': False}  1297   26   \n",
      "25381        17531     890  1.0  5.0  {'was_impossible': False}    20  176   \n",
      "50579         1696    1571  1.0  5.0  {'was_impossible': False}    78   69   \n",
      "76566         2706   21086  1.0  5.0  {'was_impossible': False}    61   17   \n",
      "140738        5260     678  1.0  5.0  {'was_impossible': False}    46   51   \n",
      "50948          317   80685  1.0  5.0  {'was_impossible': False}   206    1   \n",
      "133395          10    1999  1.0  5.0  {'was_impossible': False}  1297   28   \n",
      "\n",
      "        err  \n",
      "35996   4.0  \n",
      "219408  4.0  \n",
      "39115   4.0  \n",
      "22671   4.0  \n",
      "25381   4.0  \n",
      "50579   4.0  \n",
      "76566   4.0  \n",
      "140738  4.0  \n",
      "50948   4.0  \n",
      "133395  4.0  \n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6f396",
   "metadata": {
    "id": "2bb6f396"
   },
   "source": [
    "#### BaselineOnly HPO using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GQlh_R9yz6vd",
   "metadata": {
    "id": "GQlh_R9yz6vd"
   },
   "source": [
    "<font size=\"4\">Define the parameters for the grid search <font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77eb3b6",
   "metadata": {
    "id": "d77eb3b6",
    "outputId": "e32c12da-ae02-4aff-c634-d0f1013a0d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineOnly HPO using Grid Search Minimized:\n",
      "\n",
      "\n",
      "Grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bsl_options': {'method': ['als', 'sgd'],\n",
       "  'n_epochs': [5, 10, 15, 20],\n",
       "  'reg_u': [5, 10, 15, 20],\n",
       "  'reg_i': [5, 10, 15, 20]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('BaselineOnly HPO using Grid Search Minimized:')\n",
    "print('\\n')\n",
    "param_grid = {'bsl_options': {'method': ['als', 'sgd'],\n",
    "                             'n_epochs': [5, 10, 15, 20],\n",
    "                             'reg_u': [5, 10, 15, 20],\n",
    "                             'reg_i': [5, 10, 15, 20]}}\n",
    "print('Grid search parameters:')\n",
    "param_grid          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCI_7xSzzVSu",
   "metadata": {
    "id": "yCI_7xSzzVSu"
   },
   "source": [
    "<font size=\"4\">Run grid search with `rmse` and `mae` as the metrics. Then use the parameters that resulted in the lowest RMSE on the train/test sets<font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c750286",
   "metadata": {
    "id": "2c750286",
    "outputId": "799878fa-c00a-469e-e1a0-0d01bd1030fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating grid search parameters..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  4.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iterating grid search parameters: 410.2233831882477\n",
      "\n",
      "\n",
      "Lowest RMSE from Grid Search:\n",
      "0.9453093755322367\n",
      "\n",
      "\n",
      "Parameters of Model with lowest RMSE from Grid Search:\n",
      "{'bsl_options': {'method': 'als', 'n_epochs': 20, 'reg_u': 5, 'reg_i': 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:  6.7min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse', 'mae'], cv=3,\n",
    "                  joblib_verbose=-1, n_jobs=-1)\n",
    "print('Time for iterating grid search parameters..')\n",
    "search_time_start = time.time()\n",
    "gs.fit(data)\n",
    "print('Finished iterating grid search parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Lowest RMSE from Grid Search:')\n",
    "print(gs.best_score['rmse'])\n",
    "print('\\n')\n",
    "print('Parameters of Model with lowest RMSE from Grid Search:')\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HUyfyJWqyt9q",
   "metadata": {
    "id": "HUyfyJWqyt9q"
   },
   "source": [
    "<font size=\"4\">Fit and predict on the best model, apply functions and save prediction results <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836ae4d",
   "metadata": {
    "id": "2836ae4d",
    "outputId": "59c24a22-1dad-4f72-830d-9b4b0c54cf2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9418\n",
      "0.9418294572167315\n"
     ]
    }
   ],
   "source": [
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./BaselineOnly_bestGrid_Model_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./BaselineOnly_bestGrid_Model_file')\n",
    "   \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)\n",
    "df1.to_csv('predictions_BaselineOnly_gridSearch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z73y6lavvAPz",
   "metadata": {
    "id": "Z73y6lavvAPz"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b4cb1",
   "metadata": {
    "id": "9e7b4cb1",
    "outputId": "25f71f62-f459-49f1-abc1-b2042950958d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "191694       10879    2578  5.0  5.0  {'was_impossible': False}   28   30  0.0\n",
      "50481        10448     300  5.0  5.0  {'was_impossible': False}   28  190  0.0\n",
      "12633         9398    1087  5.0  5.0  {'was_impossible': False}   31   98  0.0\n",
      "82689          869     306  5.0  5.0  {'was_impossible': False}  120   52  0.0\n",
      "82686         4469     270  5.0  5.0  {'was_impossible': False}   52  459  0.0\n",
      "174741        1283    2020  5.0  5.0  {'was_impossible': False}   91   88  0.0\n",
      "25555         6659    7980  5.0  5.0  {'was_impossible': False}   36   11  0.0\n",
      "82667          464    2305  5.0  5.0  {'was_impossible': False}  185   77  0.0\n",
      "82663          164    4373  5.0  5.0  {'was_impossible': False}  314   54  0.0\n",
      "174729         484    8362  5.0  5.0  {'was_impossible': False}  172   18  0.0\n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QntVkMt9wPGN",
   "metadata": {
    "id": "QntVkMt9wPGN"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5152d",
   "metadata": {
    "id": "eed5152d",
    "outputId": "59aa384a-2370-461d-d067-f0f3c378031b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details    Iu   Ui  \\\n",
      "33420         4933     752  1.0  5.0  {'was_impossible': False}    43  209   \n",
      "108646        8302      20  1.0  5.0  {'was_impossible': False}    32   53   \n",
      "11064        10089    2718  1.0  5.0  {'was_impossible': False}    28   90   \n",
      "118238        8688   12360  1.0  5.0  {'was_impossible': False}    30   13   \n",
      "56860         2159    3181  5.0  1.0  {'was_impossible': False}    75   53   \n",
      "17953        11474   10529  1.0  5.0  {'was_impossible': False}    25   42   \n",
      "199058       10055     577  1.0  5.0  {'was_impossible': False}    27  218   \n",
      "11370         1747    1823  1.0  5.0  {'was_impossible': False}    76   72   \n",
      "198775          10    2632  1.0  5.0  {'was_impossible': False}  1270  127   \n",
      "99311         1094   12926  1.0  5.0  {'was_impossible': False}   102   18   \n",
      "\n",
      "        err  \n",
      "33420   4.0  \n",
      "108646  4.0  \n",
      "11064   4.0  \n",
      "118238  4.0  \n",
      "56860   4.0  \n",
      "17953   4.0  \n",
      "199058  4.0  \n",
      "11370   4.0  \n",
      "198775  4.0  \n",
      "99311   4.0  \n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mGSBZdLmJSO3",
   "metadata": {
    "id": "mGSBZdLmJSO3"
   },
   "source": [
    "#### BaselineOnly HPO using Grid Search - More Params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70adede7",
   "metadata": {
    "id": "70adede7",
    "outputId": "a22c592b-12e9-45b4-ff2c-25ad03001729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineOnly HPO using Grid Search Minimized:\n",
      "\n",
      "\n",
      "Grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bsl_options': {'method': ['als', 'sgd'],\n",
       "  'n_epochs': [10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
       "  'reg_u': [0, 1, 2, 3, 4, 5, 10, 15, 20],\n",
       "  'reg_i': [0, 1, 2, 3, 4, 5, 10, 15, 20]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('BaselineOnly HPO using Grid Search Minimized:')\n",
    "print('\\n')\n",
    "param_grid = {'bsl_options': {'method': ['als', 'sgd'],\n",
    "                             'n_epochs': [10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                             'reg_u': [0, 1, 2, 3, 4, 5, 10, 15, 20],\n",
    "                             'reg_i': [0, 1, 2, 3, 4,5, 10, 15, 20]}}\n",
    "print('Grid search parameters:')\n",
    "param_grid          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EEaPIghzzWZn",
   "metadata": {
    "id": "EEaPIghzzWZn"
   },
   "source": [
    "<font size=\"4\">Run grid search with `rmse` and `mae` as the metrics. Then use the parameters that resulted in the lowest RMSE on the train/test sets<font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d85ab",
   "metadata": {
    "id": "351d85ab",
    "outputId": "7eb5bf89-41d0-41bc-e584-f03bc75e3a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating grid search parameters..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2560 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3496 tasks      | elapsed: 63.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iterating grid search parameters: 4817.081090688705\n",
      "\n",
      "\n",
      "Lowest RMSE from Grid Search:\n",
      "0.9429468447894139\n",
      "\n",
      "\n",
      "Parameters of Model with lowest RMSE from Grid Search:\n",
      "{'bsl_options': {'method': 'als', 'n_epochs': 50, 'reg_u': 1, 'reg_i': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4374 out of 4374 | elapsed: 80.2min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse', 'mae'], cv=3,\n",
    "                  joblib_verbose=-1, n_jobs=-1)\n",
    "print('Time for iterating grid search parameters..')\n",
    "search_time_start = time.time()\n",
    "gs.fit(data)\n",
    "print('Finished iterating grid search parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Lowest RMSE from Grid Search:')\n",
    "print(gs.best_score['rmse'])\n",
    "print('\\n')\n",
    "print('Parameters of Model with lowest RMSE from Grid Search:')\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9jBJGIN8yxlI",
   "metadata": {
    "id": "9jBJGIN8yxlI"
   },
   "source": [
    "<font size=\"4\">Fit and predict on the best model, apply functions and save prediction results <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062c244",
   "metadata": {
    "id": "7062c244",
    "outputId": "cf9fe0fe-40ef-4cd9-c6e5-2c1898269b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9400\n",
      "0.9400458413742169\n"
     ]
    }
   ],
   "source": [
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./BaselineOnly_moreParams_bestGrid_Model_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./BaselineOnly_moreParams_bestGrid_Model_file')\n",
    "    \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)\n",
    "df1.to_csv('predictions_BaselineOnly_moreParams_gridSearch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1NWwHpuavCqY",
   "metadata": {
    "id": "1NWwHpuavCqY"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7769c47",
   "metadata": {
    "id": "e7769c47",
    "outputId": "32433711-01fe-4a1f-9dec-e3ec070d01aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "111339       14872     757  5.0  5.0  {'was_impossible': False}   19  107  0.0\n",
      "204037        1218    7653  5.0  5.0  {'was_impossible': False}   98   32  0.0\n",
      "74750        12389   18648  5.0  5.0  {'was_impossible': False}   29   17  0.0\n",
      "158992       11073     306  5.0  5.0  {'was_impossible': False}   22   52  0.0\n",
      "204044        5800     366  5.0  5.0  {'was_impossible': False}   38  365  0.0\n",
      "204054       16798    2016  5.0  5.0  {'was_impossible': False}   22   50  0.0\n",
      "158983        7591   13388  5.0  5.0  {'was_impossible': False}   33   12  0.0\n",
      "158982       16037   20893  5.0  5.0  {'was_impossible': False}   18    6  0.0\n",
      "204055         476    4689  5.0  5.0  {'was_impossible': False}  174   25  0.0\n",
      "158978        2180      87  5.0  5.0  {'was_impossible': False}   66  694  0.0\n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-34wHvAtwRkr",
   "metadata": {
    "id": "-34wHvAtwRkr"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79b94c",
   "metadata": {
    "id": "3e79b94c",
    "outputId": "fe12b03f-6607-4769-a5a9-75aeee84cb79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est                    details   Iu   Ui  err\n",
      "162516        6479     148  1.0  5.0  {'was_impossible': False}   40  450  4.0\n",
      "220011       15523    6988  1.0  5.0  {'was_impossible': False}   19   21  4.0\n",
      "126619        5904    1667  1.0  5.0  {'was_impossible': False}   36  105  4.0\n",
      "99713         3612   65249  1.0  5.0  {'was_impossible': False}   44    1  4.0\n",
      "99311         1094   12926  1.0  5.0  {'was_impossible': False}  102   18  4.0\n",
      "13116         3284    3483  1.0  5.0  {'was_impossible': False}   54  101  4.0\n",
      "54348        11448   61254  1.0  5.0  {'was_impossible': False}   29    4  4.0\n",
      "108646        8302      20  1.0  5.0  {'was_impossible': False}   32   53  4.0\n",
      "26866         4268    2680  1.0  5.0  {'was_impossible': False}   45   14  4.0\n",
      "96274          458    7802  1.0  5.0  {'was_impossible': False}  163   22  4.0\n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848333e",
   "metadata": {
    "id": "9848333e"
   },
   "source": [
    "### KNNBaseline\n",
    "Fit model with default parameters for 3 epochs using `method='als'` and examine RMSE on train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723fe3d",
   "metadata": {
    "id": "8723fe3d",
    "outputId": "8428020e-a826-4292-ff9b-b5807c09c9e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/predict using KNNBaseline default parameters with Alternating Least Squares for 3 epochs:\n",
      "\n",
      "\n",
      "Baselines estimates configuration:\n",
      "{'method': 'als', 'n_epochs': 3}\n",
      "\n",
      "\n",
      "Model parameters:\n",
      "KNNBaseline(k=40, min_k=1, bsl_options=bsl_options, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print('Train/predict using KNNBaseline default parameters with Alternating Least Squares for 3 epochs:')\n",
    "print('\\n')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 3}\n",
    "print('Baselines estimates configuration:')\n",
    "print(bsl_options)\n",
    "print('\\n')\n",
    "print('Model parameters:')\n",
    "print('KNNBaseline(k=40, min_k=1, bsl_options=bsl_options, verbose=False)') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pTH34Gn97Bs5",
   "metadata": {
    "id": "pTH34Gn97Bs5"
   },
   "source": [
    "<font size=\"4\">Cross validation, Fit and predict on best model with the lowest rmse, apply functions and save prediction results  <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e62e1c",
   "metadata": {
    "id": "26e62e1c",
    "outputId": "ce1f55b2-38d3-4e5e-9a66-d7988fe14d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating through KNNBaseline default parameters epochs=3 using ALS..\n",
      "Finished iterating through KNNBaseline default parameters epochs=3 using ALS: 52.3457145690918\n",
      "\n",
      "\n",
      "Cross validation results:\n",
      "test_rmse  :  [0.98871454 0.98392946 0.98468003]\n",
      "test_mae  :  [0.70193266 0.6991709  0.69981287]\n",
      "fit_time  :  (12.814245462417603, 12.74767255783081, 12.50976276397705)\n",
      "test_time  :  (27.62490439414978, 28.00885558128357, 28.005619525909424)\n"
     ]
    }
   ],
   "source": [
    "print('Time for iterating through KNNBaseline default parameters epochs=3 using ALS..')\n",
    "search_time_start = time.time()\n",
    "algo = KNNBaseline(bsl_options=bsl_options)\n",
    "cv = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=False, \n",
    "                    n_jobs=-1)\n",
    "print('Finished iterating through KNNBaseline default parameters epochs=3 using ALS:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Cross validation results:')\n",
    "# Iterate over key/value pairs in cv results dict \n",
    "for key, value in cv.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8657e0",
   "metadata": {
    "id": "3d8657e0",
    "outputId": "76af9794-1537-4184-8db1-741bb0ba8aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9639\n",
      "0.9638924023238667\n"
     ]
    }
   ],
   "source": [
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "dump.dump('./KNNBaseline_3epochs_DefaultParamModel_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./KNNBaseline_3epochs_DefaultParamModel_file')\n",
    "  \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)  \n",
    "df1.to_csv('predictions_KNNBaseline_DefaultParamModel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dp6H6o3OvE7B",
   "metadata": {
    "id": "Dp6H6o3OvE7B"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b01582",
   "metadata": {
    "id": "f1b01582",
    "outputId": "38ce1adb-3678-4522-dc00-560a0cc84412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est  \\\n",
      "82292         7359     599  5.0  5.0   \n",
      "66702        10988    1054  5.0  5.0   \n",
      "199042        3797    4924  5.0  5.0   \n",
      "66720          305    5079  5.0  5.0   \n",
      "66728        13455    1670  5.0  5.0   \n",
      "66730          567   10371  5.0  5.0   \n",
      "199038        3490   20933  5.0  5.0   \n",
      "66697        16570   33621  5.0  5.0   \n",
      "66734         4546   10521  5.0  5.0   \n",
      "66745        12943   32981  5.0  5.0   \n",
      "\n",
      "                                          details   Iu   Ui  err  \n",
      "82292   {'actual_k': 40, 'was_impossible': False}   36  104  0.0  \n",
      "66702   {'actual_k': 40, 'was_impossible': False}   26  257  0.0  \n",
      "199042  {'actual_k': 40, 'was_impossible': False}   47   73  0.0  \n",
      "66720   {'actual_k': 40, 'was_impossible': False}  226   57  0.0  \n",
      "66728    {'actual_k': 3, 'was_impossible': False}   24   13  0.0  \n",
      "66730    {'actual_k': 5, 'was_impossible': False}  153    5  0.0  \n",
      "199038   {'actual_k': 9, 'was_impossible': False}   49   15  0.0  \n",
      "66697    {'actual_k': 1, 'was_impossible': False}   23    9  0.0  \n",
      "66734    {'actual_k': 1, 'was_impossible': False}   47    5  0.0  \n",
      "66745    {'actual_k': 2, 'was_impossible': False}   26    8  0.0  \n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943dATdBwUfM",
   "metadata": {
    "id": "943dATdBwUfM"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198572f",
   "metadata": {
    "id": "8198572f",
    "outputId": "045e9288-c727-4f9e-ea56-f9046937ca73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est  \\\n",
      "50924         1518   41193  5.0  1.0   \n",
      "162946        5015    3768  1.0  5.0   \n",
      "64718         3387    2240  1.0  5.0   \n",
      "121979       14782   46077  1.0  5.0   \n",
      "87343         5468    6536  1.0  5.0   \n",
      "1375            76   55298  5.0  1.0   \n",
      "37276         3867   22619  5.0  1.0   \n",
      "128317       17696   24076  1.0  5.0   \n",
      "21647        11177   44655  5.0  1.0   \n",
      "7373          1420   28629  1.0  5.0   \n",
      "\n",
      "                                          details   Iu  Ui  err  \n",
      "50924    {'actual_k': 1, 'was_impossible': False}   85   5  4.0  \n",
      "162946   {'actual_k': 6, 'was_impossible': False}   43  21  4.0  \n",
      "64718   {'actual_k': 22, 'was_impossible': False}   49  66  4.0  \n",
      "121979   {'actual_k': 1, 'was_impossible': False}   23   1  4.0  \n",
      "87343    {'actual_k': 7, 'was_impossible': False}   42  48  4.0  \n",
      "1375     {'actual_k': 2, 'was_impossible': False}  503   2  4.0  \n",
      "37276    {'actual_k': 1, 'was_impossible': False}   46   3  4.0  \n",
      "128317   {'actual_k': 1, 'was_impossible': False}   20  11  4.0  \n",
      "21647    {'actual_k': 1, 'was_impossible': False}   26   2  4.0  \n",
      "7373     {'actual_k': 2, 'was_impossible': False}   89   4  4.0  \n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb460b",
   "metadata": {
    "id": "27eb460b"
   },
   "source": [
    "#### KNNBaseline HPO using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yI9zCKUBzcWq",
   "metadata": {
    "id": "yI9zCKUBzcWq"
   },
   "source": [
    "<font size=\"4\">Define the parameters for the grid search <font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86038b33",
   "metadata": {
    "id": "86038b33",
    "outputId": "c58b8470-7d8a-4efb-8141-7adb9b3835bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNNBaseline HPO using Grid Search:\n",
      "\n",
      "\n",
      "Grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bsl_options': {'method': ['als', 'sgd']},\n",
       " 'k': [30, 35, 40, 45, 50],\n",
       " 'min_k': [20, 25],\n",
       " 'random_state': [42],\n",
       " 'sim_options': {'name': ['pearson_baseline'],\n",
       "  'min_support': [5, 10],\n",
       "  'shrinkage': [0, 100]}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('KNNBaseline HPO using Grid Search:')\n",
    "print('\\n')\n",
    "param_grid = {'bsl_options': {'method': ['als', 'sgd']}, \n",
    "              'k': [30, 35, 40, 45, 50], \n",
    "              'min_k': [5, 10],\n",
    "              'random_state': [seed_value],\n",
    "              'sim_options': {'name': ['pearson_baseline'],\n",
    "                              'min_support': [5, 10],\n",
    "                              'shrinkage': [0, 100]}}\n",
    "print('Grid search parameters:')\n",
    "param_grid          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6g4QuGNrzXj7",
   "metadata": {
    "id": "6g4QuGNrzXj7"
   },
   "source": [
    "<font size=\"4\">Run grid search with `rmse` and `mae` as the metrics. Then use the parameters that resulted in the lowest RMSE on the train/test sets<font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981c5d4",
   "metadata": {
    "id": "e981c5d4",
    "outputId": "827d1562-cdfd-445e-837f-611c0536459a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time for iterating grid search parameters..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  62 tasks      | elapsed: 11.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iterating grid search parameters: 2447.833321094513\n",
      "\n",
      "\n",
      "Model with lowest RMSE:\n",
      "0.9453110845949882\n",
      "\n",
      "\n",
      "Parameters with the lowest RMSE:\n",
      "{'bsl_options': {'method': 'sgd'}, 'k': 40, 'min_k': 20, 'random_state': 42, 'sim_options': {'name': 'pearson_baseline', 'min_support': 5, 'shrinkage': 100, 'user_based': True}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 240 out of 240 | elapsed: 40.7min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(KNNBaseline, param_grid, measures=['rmse', 'mae'], cv=3, \n",
    "                  joblib_verbose=-1, n_jobs=5)\n",
    "print('Start time for iterating grid search parameters..')\n",
    "search_time_start = time.time()\n",
    "gs.fit(data)\n",
    "print('Finished iterating grid search parameters:',\n",
    "      time.time() - search_time_start)\n",
    "print('\\n')\n",
    "print('Model with lowest RMSE:')\n",
    "print(gs.best_score['rmse'])\n",
    "print('\\n')\n",
    "# Parameters with the lowest RMSE \n",
    "print('Parameters with the lowest RMSE:')\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d67537",
   "metadata": {
    "id": "c2d67537",
    "outputId": "8af80dc2-55cf-42f2-c59a-645cfe34c644",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9661\n",
      "0.9661408444802692\n",
      "\n",
      "\n",
      "KNNBaseline GridSearch HPO Cross Validation Results:\n",
      "    split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
      "57          0.948154          0.943403          0.944376        0.945311   \n",
      "49          0.948146          0.943407          0.944382        0.945312   \n",
      "41          0.948147          0.943410          0.944380        0.945313   \n",
      "65          0.948156          0.943407          0.944381        0.945315   \n",
      "73          0.948159          0.943412          0.944383        0.945318   \n",
      "\n",
      "    std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
      "57       0.002049               1         0.684004         0.681184   \n",
      "49       0.002044               2         0.683991         0.681176   \n",
      "41       0.002043               3         0.683976         0.681167   \n",
      "65       0.002048               4         0.684014         0.681194   \n",
      "73       0.002048               5         0.684022         0.681201   \n",
      "\n",
      "    split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  \\\n",
      "57         0.682815       0.682668      0.001156              3   \n",
      "49         0.682813       0.682660      0.001154              2   \n",
      "41         0.682792       0.682645      0.001152              1   \n",
      "65         0.682827       0.682678      0.001156              4   \n",
      "73         0.682833       0.682685      0.001156              5   \n",
      "\n",
      "    mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
      "57      25.691168      0.706310       23.868771       0.068006   \n",
      "49      25.694308      0.434385       23.448351       0.227522   \n",
      "41      26.553353      0.127125       23.412286       0.054376   \n",
      "65      25.864751      0.830243       24.260034       0.148637   \n",
      "73      26.718433      0.176109       24.502967       0.244623   \n",
      "\n",
      "                                               params  param_bsl_options  \\\n",
      "57  {'bsl_options': {'method': 'sgd'}, 'k': 40, 'm...  {'method': 'sgd'}   \n",
      "49  {'bsl_options': {'method': 'sgd'}, 'k': 35, 'm...  {'method': 'sgd'}   \n",
      "41  {'bsl_options': {'method': 'sgd'}, 'k': 30, 'm...  {'method': 'sgd'}   \n",
      "65  {'bsl_options': {'method': 'sgd'}, 'k': 45, 'm...  {'method': 'sgd'}   \n",
      "73  {'bsl_options': {'method': 'sgd'}, 'k': 50, 'm...  {'method': 'sgd'}   \n",
      "\n",
      "    param_k  param_min_k  param_random_state  \\\n",
      "57       40           20                  42   \n",
      "49       35           20                  42   \n",
      "41       30           20                  42   \n",
      "65       45           20                  42   \n",
      "73       50           20                  42   \n",
      "\n",
      "                                    param_sim_options  \n",
      "57  {'name': 'pearson_baseline', 'min_support': 5,...  \n",
      "49  {'name': 'pearson_baseline', 'min_support': 5,...  \n",
      "41  {'name': 'pearson_baseline', 'min_support': 5,...  \n",
      "65  {'name': 'pearson_baseline', 'min_support': 5,...  \n",
      "73  {'name': 'pearson_baseline', 'min_support': 5,...  \n"
     ]
    }
   ],
   "source": [
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "print('\\n')\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df = results_df.sort_values('mean_test_rmse', ascending=True)\n",
    "print('KNNBaseline GridSearch HPO Cross Validation Results:')\n",
    "print(results_df.head())\n",
    "results_df.to_csv('KNNBaseline_gridSearch_cvResults.csv', index=False)\n",
    "\n",
    "del results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gR1V5Quey6tJ",
   "metadata": {
    "id": "gR1V5Quey6tJ"
   },
   "source": [
    "<font size=\"4\">Fit and predict on the best model, apply functions and save prediction results <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd797e",
   "metadata": {
    "id": "eccd797e",
    "outputId": "018eebc0-9140-4c50-b31d-ee8d1d4a1b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE from fit best parameters on train predict on test:\n",
      "RMSE: 0.9379\n",
      "0.9378743356689234\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "predictions = algo.fit(train).test(test)\n",
    "print('RMSE from fit best parameters on train predict on test:')\n",
    "print(accuracy.rmse(predictions))\n",
    "print('\\n')\n",
    "dump.dump('./KNNBaseline_bestGrid_Model_file', predictions, algo)\n",
    "#predictions, algo = dump.load('./KNNBaseline_bestGrid_Model_file')\n",
    "   \n",
    "df1 = pd.DataFrame(predictions, columns=['reviewerID', 'itemID', 'rui', 'est',\n",
    "                                         'details'])\n",
    "df1['Iu'] = df1.reviewerID.apply(get_Ir)\n",
    "df1['Ui'] = df1.itemID.apply(get_Ri)\n",
    "df1['err'] = abs(df1.est - df1.rui)   \n",
    "df1.to_csv('predictions_KNNBaseline_gridSearch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u7QXMtqbvJmw",
   "metadata": {
    "id": "u7QXMtqbvJmw"
   },
   "source": [
    "<font size=\"4\">Find the best predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4195a",
   "metadata": {
    "id": "94b4195a",
    "outputId": "31c6330f-9fae-4b9c-fe65-f2aa2047e703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 predictions:\n",
      "        reviewerID  itemID  rui  est  \\\n",
      "90940         4608     211  5.0  5.0   \n",
      "159489       18439   14836  5.0  5.0   \n",
      "134670       12176    3672  5.0  5.0   \n",
      "41605         5787      90  5.0  5.0   \n",
      "214781       16444     188  5.0  5.0   \n",
      "14334         7397    1319  5.0  5.0   \n",
      "41607          602    8628  5.0  5.0   \n",
      "200020        8201   17834  5.0  5.0   \n",
      "41613         8629    7599  5.0  5.0   \n",
      "91520         6810     874  5.0  5.0   \n",
      "\n",
      "                                          details   Iu   Ui  err  \n",
      "90940    {'actual_k': 6, 'was_impossible': False}   48  231  0.0  \n",
      "159489   {'actual_k': 2, 'was_impossible': False}   17   26  0.0  \n",
      "134670   {'actual_k': 0, 'was_impossible': False}   24   54  0.0  \n",
      "41605    {'actual_k': 1, 'was_impossible': False}   40  152  0.0  \n",
      "214781   {'actual_k': 2, 'was_impossible': False}   20   96  0.0  \n",
      "14334    {'actual_k': 2, 'was_impossible': False}   35   96  0.0  \n",
      "41607    {'actual_k': 0, 'was_impossible': False}  133    7  0.0  \n",
      "200020   {'actual_k': 0, 'was_impossible': False}   33    4  0.0  \n",
      "41613    {'actual_k': 0, 'was_impossible': False}   33   31  0.0  \n",
      "91520   {'actual_k': 25, 'was_impossible': False}   35  261  0.0  \n"
     ]
    }
   ],
   "source": [
    "best_predictions = df1.sort_values(by='err')[:10]\n",
    "print('Best 10 predictions:')\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DPipMXWKwXtU",
   "metadata": {
    "id": "DPipMXWKwXtU"
   },
   "source": [
    "<font size=\"4\"> Find the worst predictions<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad4129",
   "metadata": {
    "id": "44ad4129",
    "outputId": "3cf82e66-eb12-4609-d053-a863dddf8588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 10 predictions:\n",
      "        reviewerID  itemID  rui  est  \\\n",
      "199613        2527     733  1.0  5.0   \n",
      "111347         302   20835  1.0  5.0   \n",
      "128997        7822     700  1.0  5.0   \n",
      "13429        10089    2718  1.0  5.0   \n",
      "135680         804   23913  1.0  5.0   \n",
      "105987        9570     388  1.0  5.0   \n",
      "145506          10    8074  1.0  5.0   \n",
      "44675         5849    4328  1.0  5.0   \n",
      "64715         3907     100  1.0  5.0   \n",
      "201633        3958    1842  5.0  1.0   \n",
      "\n",
      "                                          details    Iu   Ui  err  \n",
      "199613   {'actual_k': 5, 'was_impossible': False}    65  417  4.0  \n",
      "111347   {'actual_k': 0, 'was_impossible': False}   218    5  4.0  \n",
      "128997   {'actual_k': 4, 'was_impossible': False}    34  114  4.0  \n",
      "13429    {'actual_k': 0, 'was_impossible': False}    30   87  4.0  \n",
      "135680   {'actual_k': 0, 'was_impossible': False}   122    5  4.0  \n",
      "105987   {'actual_k': 0, 'was_impossible': False}    25  299  4.0  \n",
      "145506   {'actual_k': 8, 'was_impossible': False}  1307   38  4.0  \n",
      "44675    {'actual_k': 1, 'was_impossible': False}    40   71  4.0  \n",
      "64715   {'actual_k': 26, 'was_impossible': False}    49  452  4.0  \n",
      "201633   {'actual_k': 0, 'was_impossible': False}    54   29  4.0  \n"
     ]
    }
   ],
   "source": [
    "worst_predictions = df1.sort_values(by='err')[-10:]\n",
    "print('Worst 10 predictions:')\n",
    "print(worst_predictions)\n",
    "\n",
    "del predictions, df1, best_predictions, worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fbf4ae",
   "metadata": {
    "id": "f2fbf4ae"
   },
   "source": [
    "## RecSys Methods without Surprise\n",
    "### Create the rating matrix with items and reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844e476",
   "metadata": {
    "id": "b844e476"
   },
   "source": [
    "### Create SVD Based Recommendation System using SciPy\n",
    "<font size=\"4\">For the training of the SVD based models using `SciPy`:\n",
    "A rating matrix with reviewers and items was constructed and transposed. The parameters for the model were `U, sigma, Vt = randomized_svd(ratingsMat, n_components, n_oversamples, random_state)`. A diagonal matrix was constructed in SVD. Then the ratings were predicted and RMSE was calculated. <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b5428",
   "metadata": {
    "id": "3f9b5428",
    "outputId": "126dcc7f-b834-417e-9823-cb59b74aeb54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103687, 19639)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create user-item matrix & transpose the utility matrix\n",
    "ratingsMat = df.pivot_table(values='rating', index='reviewer_id', \n",
    "                            columns='item_id', fill_value=0)\n",
    "X = ratingsMat.values.T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b489ce2b",
   "metadata": {
    "id": "b489ce2b"
   },
   "source": [
    "### Model with `n_components=15` and `n_oversamples=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168855c",
   "metadata": {
    "id": "7168855c"
   },
   "outputs": [],
   "source": [
    "# Define model components\n",
    "U, sigma, Vt = randomized_svd(X, n_components=15, \n",
    "                              n_oversamples=20, random_state=42)\n",
    "\n",
    "# Construct a diagonal matrix in SVD\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Predicted rating\n",
    "reviewers_predRating = np.dot(np.dot(U, sigma), Vt) \n",
    "\n",
    "# Create a dataframe of the predicted ratings\n",
    "ratingPred = pd.DataFrame(reviewers_predRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ec581",
   "metadata": {
    "id": "ef3ec581",
    "outputId": "8d4bcba9-db6b-4584-994b-2ffeaa0dfaba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate the SciPy SVD Collaborative recommender model\n",
      "\n",
      "RMSE of SciPy SVD Model = 0.0144595486 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nEvaluate the SciPy SVD Collaborative recommender model')\n",
    "rmse_df = pd.concat([ratingsMat.mean(), ratingPred.mean()], axis=1)\n",
    "rmse_df.columns = ['Avg_actual_rating', 'Avg_predicted_rating']\n",
    "rmse_df['item_index'] = np.arange(0, rmse_df.shape[0], 1)\n",
    "\n",
    "RMSE = round((((rmse_df.Avg_actual_rating \n",
    "                - rmse_df.Avg_predicted_rating) ** 2).mean() ** 0.5), 10)\n",
    "print('\\nRMSE of SciPy SVD Model = {} \\n'.format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8HsinfkOnxQH",
   "metadata": {
    "id": "8HsinfkOnxQH"
   },
   "source": [
    "### Model with `n_components=10` and `n_oversamples=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c948f64",
   "metadata": {
    "id": "4c948f64"
   },
   "outputs": [],
   "source": [
    "# Define model components\n",
    "U, sigma, Vt = randomized_svd(X, n_components=10,\n",
    "                              n_oversamples=20, random_state=42)\n",
    "\n",
    "# Construct a diagonal matrix in SVD\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Predicted rating\n",
    "reviewers_predRating = np.dot(np.dot(U, sigma), Vt) \n",
    "\n",
    "# Create a dataframe of the predicted ratings\n",
    "ratingPred = pd.DataFrame(reviewers_predRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653ebf6",
   "metadata": {
    "id": "a653ebf6",
    "outputId": "fef1c4b6-fc62-48c2-96b1-d4223f906eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate the SciPy SVD Collaborative recommender model\n",
      "\n",
      "RMSE of SciPy SVD Model = 0.0144523715 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nEvaluate the SciPy SVD Collaborative recommender model')\n",
    "rmse_df = pd.concat([ratingsMat.mean(), ratingPred.mean()], axis=1)\n",
    "rmse_df.columns = ['Avg_actual_rating', 'Avg_predicted_rating']\n",
    "rmse_df['item_index'] = np.arange(0, rmse_df.shape[0], 1)\n",
    "\n",
    "RMSE = round((((rmse_df.Avg_actual_rating \n",
    "                - rmse_df.Avg_predicted_rating) ** 2).mean() ** 0.5), 10)\n",
    "print('\\nRMSE of SciPy SVD Model = {} \\n'.format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hylzxMFF6Mi9",
   "metadata": {
    "id": "hylzxMFF6Mi9"
   },
   "source": [
    "<a id=\"decompose-matrix\"></a>\n",
    "<font size=\"4\">**Decomposing the Matrix**\n",
    "\n",
    "`TruncatedSVD` from `sklearn` was used to to compress the transposed matrix down to a number of rows by different number of matrices. The `items` are in the rows. while the `users` are compressed down to `X components`, providing a way to examine a generalized perspective of the users' interests with this given set.  <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Och25v3z6Mi-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "Och25v3z6Mi-",
    "outputId": "66f1bdfa-1ff1-49dd-f1dc-2799fdd47143"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103687, 500)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD = TruncatedSVD(n_components=12, random_state=seed_value)\n",
    "result_matrix = SVD.fit_transform(X)\n",
    "result_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123a237",
   "metadata": {
    "id": "4123a237",
    "outputId": "ffe1892a-409c-494f-824e-cd0f12bb0b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103687, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD = TruncatedSVD(n_components=50, random_state=seed_value)\n",
    "result_matrix = SVD.fit_transform(X)\n",
    "result_matrix1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etpyLB0j6Mi_",
   "metadata": {
    "id": "etpyLB0j6Mi_"
   },
   "source": [
    "<a id=\"gen-corr-matrix\"></a>\n",
    "<font size=\"4\">**Generating a Correlation Matrix**\n",
    "\n",
    "PearsonR coefficient was calculated for every item pair in the result_matrix based on similarities between users' interests. `numpy.memmap` was utilized due to the memory constraints of sparse data. This involved splitting the input in 1000 row chucks, subtract means form the input data, and normalizing to create the correlation matrix.<font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KWy2T6LK6MjA",
   "metadata": {
    "id": "KWy2T6LK6MjA",
    "outputId": "fe52a153-dff1-499d-94de-155bc75c51bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103687, 103687)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLITROWS = 1000\n",
    "numrows = result_matrix.shape[0]\n",
    "\n",
    "result_matrix -= np.mean(result_matrix, axis=1)[:,None]\n",
    "\n",
    "result_matrix /= np.sqrt(np.sum(result_matrix * result_matrix, axis=1))[:,None]\n",
    "\n",
    "corr_matrix = np.memmap('/mydata.dat', 'float64', mode='w+', \n",
    "                        shape=(numrows, numrows)) \n",
    "\n",
    "for r in range(0, numrows, SPLITROWS):\n",
    "    for c in range(0, numrows, SPLITROWS):\n",
    "        r1 = r + SPLITROWS\n",
    "        c1 = c + SPLITROWS\n",
    "        chunk1 = result_matrix[r:r1]\n",
    "        chunk2 = result_matrix[c:c1]\n",
    "        corr_matrix[r:r1, c:c1] = np.dot(chunk1, chunk2.T)\n",
    "corr_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y-yVO2Xc6MjB",
   "metadata": {
    "id": "Y-yVO2Xc6MjB"
   },
   "source": [
    "<a id=\"isolate\"></a>\n",
    "<font size=\"4\">**Extract the most popular item from the Correlation Matrix**\n",
    "\n",
    "The most popular `item_id=8`. The correlation values are then extracted between `item_id=8` and all other items in the matrix. <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc5aca",
   "metadata": {
    "id": "3bcc5aca",
    "outputId": "b3b82697-8429-4592-b567-fe07736859ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of the popular item:  8\n"
     ]
    }
   ],
   "source": [
    "item_names = ratingsMat.columns\n",
    "item_list = list(item_names)\n",
    "item_list\n",
    "\n",
    "popular_item = item_list.index(8)\n",
    "print('index of the popular item: ', popular_item) \n",
    " \n",
    "corr_popular_item = corr_matrix[popular_item]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tPH97hJd6MjD",
   "metadata": {
    "id": "tPH97hJd6MjD"
   },
   "source": [
    "<a id=\"recommend\"></a>\n",
    "<font size=\"4\">**Recommend Highly Correlated Items**\n",
    "\n",
    "Now filter out the most correlated item to \"Add item\" by applying the following conditions as shown below. <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aac257",
   "metadata": {
    "id": "d0aac257"
   },
   "source": [
    "#### 12 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZD_nfs7PqbpV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZD_nfs7PqbpV",
    "outputId": "7bfd9fea-fdc9-42f2-fc1d-ef5ecfc555e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items > 0.9 correlated with target: 87\n",
      "Number of items > 0.95 correlated with target: 7\n",
      "Items > 0.95 correlated with target: [17, 11062, 26414, 29303, 34289, 40162, 54404]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list items that are greater 0.9 correlated with target\n",
    "a = list(item_names[(corr_popular_item < 1.0) & (corr_popular_item > 0.90)])\n",
    "print('Number of items > 0.9 correlated with target:', len(a))\n",
    "\n",
    "# Construct a list items that are greater 0.95 correlated with target\n",
    "b = list(item_names[(corr_popular_item < 1.0) & (corr_popular_item > 0.95)])\n",
    "print('Number of items > 0.95 correlated with target:', len(b))\n",
    "print('Items > 0.95 correlated with target:', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c6293",
   "metadata": {
    "id": "dc2c6293"
   },
   "source": [
    "#### 50 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VmVbFbaZraTH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmVbFbaZraTH",
    "outputId": "e7e2d473-b0c7-43cb-8f67-47dff2fc2186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items > 0.9 correlated with target: 0\n",
      "Number of items > 0.8 correlated with target: 7\n",
      "Number of items > 0.7 correlated with target: 67\n",
      "Items > 0.80 correlated with target: [37141, 37478, 48025, 51623, 66472, 70981, 89506]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list items that are greater 0.9 correlated with target\n",
    "a = list(item_names[(corr_popular_item < 1.0) & (corr_popular_item > 0.90)])\n",
    "print('Number of items > 0.9 correlated with target:', len(a))\n",
    "\n",
    "# Construct a list items that are greater 0.80 correlated with target\n",
    "b = list(item_names[(corr_popular_item < 1.0) & (corr_popular_item > 0.80)])\n",
    "print('Number of items > 0.80 correlated with target:', len(b))\n",
    "\n",
    "# Construct a list items that are greater 0.70 correlated with target\n",
    "c = list(item_names[(corr_popular_item < 1.0) & (corr_popular_item > 0.70)])\n",
    "print('Number of items > 0.70 correlated with target:', len(c))\n",
    "print('Items > 0.70 correlated with target:', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed6357-fb8b-4703-880f-651b12c7528a",
   "metadata": {
    "id": "41ed6357-fb8b-4703-880f-651b12c7528a"
   },
   "source": [
    "<font size=\"4\">Recommend the items with the highest predicted rating by selecting and sorting the reviewer's rating and concatenating the actual rating with the predicted rating <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16057f77",
   "metadata": {
    "id": "16057f77"
   },
   "outputs": [],
   "source": [
    "def recommend_items(reviewerID, ratingsMat, ratingPred, num_recommendations):\n",
    "    reviewer_idx = reviewerID - 1\n",
    "    \n",
    "    sorted_reviewer_rating = ratingsMat.iloc[reviewer_idx].sort_values(ascending=False)\n",
    "    sorted_reviewer_predictions = ratingPred.iloc[reviewer_idx].sort_values(ascending=False)\n",
    "\n",
    "    tmp = pd.concat([sorted_reviewer_rating, sorted_reviewer_predictions], \n",
    "                     axis=1)\n",
    "    tmp.index.name = 'Recommended Items'\n",
    "    tmp.columns = ['reviewer_rating', 'reviewer_predictions']\n",
    "    tmp = tmp.sort_values('reviewer_predictions', ascending=False)\n",
    "    \n",
    "    print('\\nBelow are the recommended items for reviewer(reviewer_id = {}):\\n'.format(reviewerID))\n",
    "    print(tmp.head(num_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b061027",
   "metadata": {
    "id": "5b061027",
    "outputId": "7dc30063-41b5-4f05-bad0-7660144781a3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below are the recommended items for reviewer(reviewer_id = 1):\n",
      "\n",
      "                   reviewer_rating  reviewer_predictions\n",
      "Recommended Items                                       \n",
      "9                              5.0              5.717030\n",
      "34                             5.0              3.476725\n",
      "46                             0.0              2.600543\n",
      "3                              0.0              2.251135\n",
      "33                             0.0              2.209918\n",
      "43                             0.0              2.184715\n",
      "42                             3.0              2.123471\n",
      "39                             0.0              2.057666\n",
      "55                             4.0              1.968689\n",
      "173                            4.0              1.875312\n",
      "\n",
      "Below are the recommended items for reviewer(reviewer_id = 40):\n",
      "\n",
      "                   reviewer_rating  reviewer_predictions\n",
      "Recommended Items                                       \n",
      "0                              0.0              2.102204\n",
      "13                             0.0              2.044710\n",
      "2                              0.0              2.023067\n",
      "17                             0.0              1.289885\n",
      "20                             0.0              1.278883\n",
      "27                             5.0              1.203790\n",
      "34                             5.0              1.184727\n",
      "322                            0.0              0.984375\n",
      "144                            0.0              0.973318\n",
      "264                            0.0              0.948870\n",
      "\n",
      "Below are the recommended items for reviewer(reviewer_id = 300):\n",
      "\n",
      "                   reviewer_rating  reviewer_predictions\n",
      "Recommended Items                                       \n",
      "10                             5.0              6.615881\n",
      "55                             0.0              3.641535\n",
      "5                              0.0              3.089970\n",
      "82                             0.0              3.079058\n",
      "11                             0.0              3.039611\n",
      "13                             4.0              2.873879\n",
      "56                             0.0              2.758218\n",
      "1                              0.0              2.708661\n",
      "14                             4.0              2.581395\n",
      "16                             4.0              2.511614\n"
     ]
    }
   ],
   "source": [
    "reviewerID = 1\n",
    "num_recommendations = 10\n",
    "recommend_items(reviewerID, ratingsMat, ratingPred, num_recommendations)\n",
    "\n",
    "reviewerID = 40\n",
    "num_recommendations = 10\n",
    "recommend_items(reviewerID, ratingsMat, ratingPred, num_recommendations)\n",
    "\n",
    "reviewerID = 300\n",
    "num_recommendations = 10\n",
    "recommend_items(reviewerID, ratingsMat, ratingPred, num_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c921a0",
   "metadata": {
    "id": "30c921a0"
   },
   "source": [
    "### Popularity Model\n",
    "<font size=\"4\">For the construction of the popularity recommender model, a recommendation score was created by counting each reviewer for each unique item. This score was sorted and a recommendation rank was created based on scoring. Then the top five recommendations were examined. <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac60fd",
   "metadata": {
    "id": "96ac60fd",
    "outputId": "ed6509c0-dbb1-4c53-c0de-806f3de29900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train set: (890561, 3)\n",
      "Dimensions of test set: (222833, 3)\n"
     ]
    }
   ],
   "source": [
    "# Examine train/test sets for modeling\n",
    "print('Dimensions of train set:', train.shape)\n",
    "print('Dimensions of test set:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e79885",
   "metadata": {
    "id": "a2e79885",
    "outputId": "010dd533-53bc-470f-bb38-65e4f35dc96e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 recommendations\n",
      "   item_id   count  rank\n",
      "4      5.0  475124   1.0\n",
      "3      4.0  202266   2.0\n",
      "2      3.0  112957   3.0\n",
      "1      2.0   52608   4.0\n",
      "0      1.0   47606   5.0\n"
     ]
    }
   ],
   "source": [
    "train_grouped = train.groupby('item_id').agg({'reviewer_id': 'count'}).reset_index()\n",
    "train_grouped.rename(columns = {'reviewer_id': 'count'}, inplace=True)\n",
    "\n",
    "train_sort = train_grouped.sort_values(['item_id', 'count'], ascending=[0,1]) \n",
    "train_sort['rank'] = train_sort['count'].rank(ascending=0, method='first') \n",
    "\n",
    "popularity_recommendations = train_sort.head() \n",
    "print('\\nTop 5 recommendations')\n",
    "print(popularity_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034ee50-785f-4f4e-a720-82cbbe5b52f0",
   "metadata": {
    "id": "a034ee50-785f-4f4e-a720-82cbbe5b52f0"
   },
   "source": [
    "<font size=\"4\">Predictions were then calculated for various reviewers by defining a function where `reviewer_id` was added as the first column for which the recommendations are generated. For three different reviewers, the same items were generated. This is not a robust methods for recommendation systems because there are lots of unaccounted for variable like age, gender, location and time to nane a few.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd41ca",
   "metadata": {
    "id": "fddd41ca",
    "outputId": "3a33bf30-6877-406b-df18-388de104ef84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of recommendations for the reviewer_id: 1\n",
      "\n",
      "   reviewer_id  item_id   count  rank\n",
      "4            1      5.0  475124   1.0\n",
      "3            1      4.0  202266   2.0\n",
      "2            1      3.0  112957   3.0\n",
      "1            1      2.0   52608   4.0\n",
      "0            1      1.0   47606   5.0\n",
      "The list of recommendations for the reviewer_id: 100\n",
      "\n",
      "   reviewer_id  item_id   count  rank\n",
      "4          100      5.0  475124   1.0\n",
      "3          100      4.0  202266   2.0\n",
      "2          100      3.0  112957   3.0\n",
      "1          100      2.0   52608   4.0\n",
      "0          100      1.0   47606   5.0\n",
      "The list of recommendations for the reviewer_id: 200\n",
      "\n",
      "   reviewer_id  item_id   count  rank\n",
      "4          200      5.0  475124   1.0\n",
      "3          200      4.0  202266   2.0\n",
      "2          200      3.0  112957   3.0\n",
      "1          200      2.0   52608   4.0\n",
      "0          200      1.0   47606   5.0\n"
     ]
    }
   ],
   "source": [
    "def recommend(reviewer_id):   \n",
    "\n",
    "    reviewer_recommendations = popularity_recommendations \n",
    "    reviewer_recommendations['reviewer_id'] = reviewer_id \n",
    "    cols = reviewer_recommendations.columns.tolist() \n",
    "    cols = cols[-1:] + cols[:-1] \n",
    "    reviewer_recommendations = reviewer_recommendations[cols] \n",
    "          \n",
    "    return reviewer_recommendations \n",
    "\n",
    "find_recom = [1,100,200]   \n",
    "for i in find_recom:\n",
    "    print('The list of recommendations for the reviewer_id: %d\\n' %(i))\n",
    "    print(recommend(i))    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
